---
title: "MCMC"
output:
  html_document:
    df_print: paged
---

```{r}
set.seed(15)

library(ggplot2)
```

# Simulation

```{r}
# parameters
A <- 1 / 2
B <- -1 / 4
b <- 1
a <- 0.1
beta <- 0.05
sigma <- 0.1
omega <- 0.01
Delta <- 1
psi <- exp(-Delta * beta)
gamma <- sigma/sqrt(2*beta)*sqrt(1-psi^2)

n <- 500
x <- 1:n

# functions
g <- function (xi, a.arg = a) {
  a.arg * x + xi
}
f <- function (xi, A.arg = A, a.arg = a, B.arg = B, b.arg = b) {
  A.arg * sin(g(xi, a.arg) + b.arg) +
          B.arg * sin(2 * g(xi, a.arg) + 2 * b.arg + pi / 2)
}
rxi <- function (xi=rep(0,n), psi.arg = psi, gamma.arg = gamma) {
  for (i in 2:length(xi)) {
    xi[[i]] <- xi[[i - 1]] * psi.arg + rnorm(1, 0, gamma.arg)
  }
  return(xi)
}
```

```{r}
plot(A * sin(g(rep(0, n), a) + b), type = "l")
```

```{r}
plot(B * sin(2 * g(rep(0, n), a) + 2 * b + pi / 2), type = "l")
```

```{r}
plot(f(rep(0, n)), type = "l")
```

```{r}
xi <- rxi(rep(0, n))

plot(xi, type = "l")
```

```{r}
Y <- f(xi) + rnorm(n, 0, omega)

plot(Y, type = "l")
```

# Sampling

```{r}
# function
log.lik <- function (xi.arg, omega.arg = omega, psi.arg = psi, gamma.arg = gamma) {
  return(sum(dnorm(Y, f(xi.arg), omega.arg, log = TRUE)) +
         sum(dnorm(xi.arg[2:length(xi.arg)], xi.arg[1:(length(xi.arg) - 1)] * psi.arg,
                   gamma.arg, log = TRUE)))
}
```


## Per process unit

```{r}
M <- 150
delta <- matrix(c(rep(.05, n),rep(NA,n*(M-1))),nrow=M,byrow=T)
delta.ar <- 0.1

xi.mcmc <- matrix(nrow = M, ncol = n)
xi.mcmc.p <- matrix(nrow = M, ncol = n)
xi.c <- rep(0,n)
accepted.n <- rep(0, n)
acceptance.rate <- matrix(nrow = M, ncol = n)
acceptance.target <- .23

for (k in 1:M) {
  for (i in 1:n) {
    xi.p <- xi.c
    xi.p[[i]] <- rnorm(1, xi.p[[i]], delta[k,i])
    xi.mcmc.p[k, i] <- xi.p[[i]]
    log.prob <- min(1, log.lik(xi.p) - log.lik(xi.c))
    if (log(runif(1)) < log.prob) {
      xi.c <- xi.p
      accepted.n[[i]] <- accepted.n[[i]] + 1
    }

    # adaptative variance
    acceptance.rate[k, i] <- accepted.n[[i]] / k
    if(k<M){
      if (acceptance.rate[k, i] < acceptance.target * (1 - .1)) {
        delta[k+1,i] <- delta[k,i] * (1 - delta.ar)
      } else if (acceptance.rate[k, i] > acceptance.target * (1 + .1)) {
        delta[k+1,i] <- delta[k,i] * (1 + delta.ar)
      } else {
        delta[k+1,i] <- delta[k,i]
      }
    }
  }
  xi.mcmc[k, ] <- xi.c
}

plot(xi, type = "l", col = "blue",
     ylim = c(min(min(xi.mcmc[nrow(xi.mcmc), ]), min(xi)), max(max(xi.mcmc[nrow(xi.mcmc), ]), max(xi))))
lines(xi.mcmc[nrow(xi.mcmc), ], type = "l", col = "red")

plot(Y, type = "l", col = "blue")
lines(f(xi.mcmc[nrow(xi.mcmc), ]), type = "l", col = "red")
```

```{r}
ggplot(data = data.frame(x = 1:M), aes(x = x)) +
        geom_line(aes(y = xi.mcmc[, which.max(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]), color = "blue") +
        geom_line(aes(y = xi.mcmc.p[, which.max(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]), color = "red") +
        geom_hline(aes(yintercept = xi[which.max(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]))

ggplot(data = data.frame(x = 1:M), aes(x = x)) +
        geom_line(aes(y = xi.mcmc[, which.min(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]), color = "blue") +
        geom_line(aes(y = xi.mcmc.p[, which.min(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]), color = "red") +
        geom_hline(aes(yintercept = xi[which.min(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]))

ggplot(data = data.frame(x = 1:M), aes(x = x)) +
        geom_line(aes(y = xi.mcmc[, which.max(abs(xi))]), color = "blue") +
        geom_line(aes(y = xi.mcmc.p[, which.max(abs(xi))]), color = "red") +
        geom_hline(aes(yintercept = xi[which.max(abs(xi))]))
```

```{r}
coeff <- max(acceptance.rate[, which.max(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]) /
        max(delta[, which.max(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))])
ggplot(data = data.frame(x = 1:M), aes(x = x)) +
        geom_line(aes(y = acceptance.rate[, which.max(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]), color = "red") +
        geom_line(aes(y = delta[, which.max(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))] * coeff), color = "blue") +
        geom_hline(aes(yintercept = .23 * 1.1), linetype = 2, color = "red") +
        geom_hline(aes(yintercept = .23 * .9), linetype = 2, color = "red") +
        scale_y_continuous(name = "Acceptance rate", sec.axis = sec_axis(~. / coeff, name = "Delta"))
coeff <- max(acceptance.rate[, which.min(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]) /
        max(delta[, which.min(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))])
ggplot(data = data.frame(x = 1:M), aes(x = x)) +
        geom_line(aes(y = acceptance.rate[, which.min(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))]), color = "red") +
        geom_line(aes(y = delta[, which.min(abs(xi - xi.mcmc[nrow(xi.mcmc), ]))] * coeff), color = "blue") +
        geom_hline(aes(yintercept = .23 * 1.1), linetype = 2, color = "red") +
        geom_hline(aes(yintercept = .23 * .9), linetype = 2, color = "red") +
        scale_y_continuous(name = "Acceptance rate", sec.axis = sec_axis(~. / coeff, name = "Delta"))
```

```{r}
which.min(xi.mcmc[nrow(xi.mcmc), ])
plot(delta[150,])
delt.test<-delta[150,]
maxs=sort(delt.test,decreasing=TRUE)[2]

indice<-457

#On regarde la colonnes des delta associée au 457ème indice 

plot(delta[,indice],main="evolution du delta de la 457eme valeurs de xi") #comportement bizarre entre 50 et 100 

#On regarde donc le comportement des xi 50:100

#par(mfrow=c(1,3))
#for(k.ind in c(80,81,82)){
 # plot(xi, type = "l", col = "blue",main=paste("k=",k.ind),
#     ylim = c(min(min(xi.mcmc[nrow(xi.mcmc), ]), min(xi)), max(max(xi.mcmc[nrow(xi.mcmc), ]), max(xi))))
#  lines(xi.mcmc[k.ind, ], type = "l", col = "red")
  
#}
```

```{r}
plot(acceptance.rate)
abline(h = acceptance.target, lty = "dashed", col = "red")
```

```{r}
plot(delta)
```

## Comparaison de xi au fil des k 

```{r}
# xi
par(mfrow=c(2,2))
for(k.ind in round(seq(1,M,length.out=10),0)){
  plot(xi, type = "l", col = "blue",
       ylim = c(min(min(xi.mcmc[nrow(xi.mcmc), ]), min(xi)), max(max(xi.mcmc[nrow(xi.mcmc), ]), max(xi))),main=paste("k= ",k.ind))
  lines(xi.mcmc[k.ind, ], type = "l", col = "red")
  
}


#Converge aux alentours de 300 
```

## Comparaison de f au fil des k 

```{r}
# f
par(mfrow=c(2,2))
for(k.ind in round(seq(1,M,length.out=10),0)){
  plot(Y, type = "l", col = "blue",main=paste("k= ",k.ind))
  lines(f(xi.mcmc[k.ind, ]), type = "l", col = "red")
}

#Converge aux alentours de 300 
```

### Identifiabilité 


```{r,fig.height=6,fig.width=9}
p1<-rxi()
p2<-rxi()
p3<-rxi()
p4<-rxi()

par(mfrow=c(2,2))

plot(p1, type = "l", col = 1,ylim=c(min(p1),max(p1)))

plot(p1, type = "l", col = 1,ylim=c(min(c(min(p1),min(p2))),max(c(max(p1),max(p2)))))
lines(p2, type = "l", col = 2)

plot(p1, type = "l", col = 1,ylim=c(min(c(min(p1),min(p3))),max(c(max(p1),max(p3)))))
lines(p3, type = "l", col = 3)

plot(p1, type = "l", col = 1,ylim=c(min(c(min(p1),min(p4))),max(c(max(p1),max(p4)))))
lines(p4, type = "l", col = 4)
```

```{r,fig.height=6,fig.width=9}

par(mfrow=c(2,2))

plot(f(p1), type = "l", col = 1)

plot(f(p1), type = "l", col = 1)
lines(f(p2), type = "l", col = 2)

plot(f(p1), type = "l", col = 1)
lines(f(p3), type = "l", col = 3)

plot(f(p1), type = "l", col = 1)
lines(f(p4), type = "l", col = 4)
```

## Comparaison du signal f(x) si on utiliser un processus xi simplement simulée ou estimé par MCMC 

```{r,fig.height=8,fig.width=11}
par(mfrow=c(2,2))
plot(Y, type = "l", col = 1,main="goal")

plot(Y, type = "l", col = 1,main="MCMC")
lines(f(xi.mcmc[nrow(xi.mcmc), ]), type = "l", col = 2)

plot(Y, type = "l", col = 1,main="xi simulation")
lines(f(xi.mcmc[nrow(xi.mcmc), ]), type = "l", col = 2)
lines(f(p1), type = "l", col = 3)

plot(Y, type = "l", col = 1,main="xi simulation")
lines(f(xi.mcmc[nrow(xi.mcmc), ]), type = "l", col = 2)
lines(f(p2), type = "l", col = 4)
```


# EM 


```{r,fig.height=8,fig.width=11}
n=500
M <- 200
J<-5
delta <- matrix(.5,ncol=n,nrow=M,byrow=T)
delta.ar <- 0.01
omega.mcmc<-rep(0,M)
omega.mcmc[1]=0.5
  
s1<-rep(0,M)

D.alpha<-90
alpha<-rep(1,M)
alpha[D.alpha:M]=1/((1:(M-(D.alpha-1)))^0.8)

xi.mcmc <- matrix(nrow = M, ncol = n)
xi.c <- rep(0,n)
accepted.n <- rep(0, n)
acceptance.rate <- rep(0, n)
acceptance.target <- .23


for (k in 2:M) {
  # Etape MCMC 
  for(j in 1:J){
  for (i in 1:n) {
    xi.p <- xi.c
    xi.p[[i]] <- rnorm(1, xi.p[[i]], delta[[k,i]])
    log.prob <- min(1, log.lik(xi.p,omega.arg=omega.mcmc[k-1]) - log.lik(xi.c,omega.arg=omega.mcmc[k-1]))
    if (log(runif(1)) < log.prob) {
      xi.c <- xi.p
      accepted.n[[i]] <- accepted.n[[i]] + 1
    }
    
    if(k<M){
      # adaptative variance
      acceptance.rate[[i]] <- accepted.n[[i]] / k
      if ((acceptance.rate[[i]] < acceptance.target * (1 - .1))||(acceptance.rate[[i]] > acceptance.target * (1 + .1))) {
        delta[k+1,i] <- delta[[k,i]] * (1 - delta.ar)
      } else{
        delta[k+1,i] <- delta[[k,i]]
      }
    }
  }
  xi.mcmc[k, ] <- xi.c
  }
  f.k=f(xi.c)
  #Etape calcul des stats exhaustives
  S1=mean((Y-f.k)^2)
  #Etape approximation stochastique
  s1[k]<-s1[k-1]+alpha[k]*(S1-s1[k-1])
  
  #Etape de maximisation 
  omega.mcmc[k]=sqrt(s1[k])
  
}

plot(xi, type = "l", col = "blue",
     ylim = c(min(min(xi.mcmc[nrow(xi.mcmc), ]), min(xi)), max(max(xi.mcmc[nrow(xi.mcmc), ]), max(xi))))
lines(xi.mcmc[nrow(xi.mcmc), ], type = "l", col = "red")

plot(omega.mcmc,type='l',col='blue')
abline(h=omega,col='red')
```


# Recherche de l'équilibre 


```{r,fig.height=12,fig.width=11}
par(mfrow=c(3,2))
for (D.alpha in c(50,70,90,100)){
n=500
M <- 200
delta <- matrix(.5,ncol=n,nrow=M,byrow=T)
delta.ar <- 0.01
omega.mcmc<-rep(0,M)
omega.mcmc[1]=0.5
  
s1<-rep(0,M)

#D.alpha<-20
alpha<-rep(1,M)
alpha[D.alpha:M]=1/((1:(M-(D.alpha-1)))^0.8)

xi.mcmc <- matrix(nrow = M, ncol = n)
xi.c <- rep(0,n)
accepted.n <- rep(0, n)
acceptance.rate <- rep(0, n)
acceptance.target <- .23


for (k in 2:M) {
  # Etape MCMC 
  for (i in 1:n) {
    xi.p <- xi.c
    xi.p[[i]] <- rnorm(1, xi.p[[i]], delta[[k,i]])
    log.prob <- min(1, log.lik(xi.p,omega.arg=omega.mcmc[k-1]) - log.lik(xi.c,omega.arg=omega.mcmc[k-1]))
    if (log(runif(1)) < log.prob) {
      xi.c <- xi.p
      accepted.n[[i]] <- accepted.n[[i]] + 1
    }
    
    if(k<M){
      # adaptative variance
      acceptance.rate[[i]] <- accepted.n[[i]] / k
      if ((acceptance.rate[[i]] < acceptance.target * (1 - .1))||(acceptance.rate[[i]] > acceptance.target * (1 + .1))) {
        delta[k+1,i] <- delta[[k,i]] * (1 - delta.ar)
      } else{
        delta[k+1,i] <- delta[[k,i]]
      }
    }
  }
  xi.mcmc[k, ] <- xi.c
  
  f.k=f(xi.c)
  #Etape calcul des stats exhaustives
  S1=mean((Y-f.k)^2)
  #Etape approximation stochastique
  s1[k]<-s1[k-1]+alpha[k]*(S1-s1[k-1])
  
  #Etape de maximisation 
  omega.mcmc[k]=sqrt(s1[k])
  
}
plot(omega.mcmc,type='l',col='blue',main=paste("D.alpha = ",D.alpha))
abline(h=omega,col='red')
}
```


## Test nb itération de MCMC dans EM 

```{r,fig.height=8,fig.width=11}
par(mfrow=c(2,2))
for (J in c(1,3,5,10)){
n=500
M <- 200
delta <- matrix(.5,ncol=n,nrow=M,byrow=T)
delta.ar <- 0.01
omega.mcmc<-rep(0,M)
omega.mcmc[1]=0.5
  
s1<-rep(0,M)

D.alpha<-90
alpha<-rep(1,M)
alpha[D.alpha:M]=1/((1:(M-(D.alpha-1)))^0.8)

xi.mcmc <- matrix(nrow = M, ncol = n)
xi.c <- rep(0,n)
accepted.n <- rep(0, n)
acceptance.rate <- rep(0, n)
acceptance.target <- .23


for (k in 2:M) {
  # Etape MCMC 
  for(j in 1:J){
  for (i in 1:n) {
    xi.p <- xi.c
    xi.p[[i]] <- rnorm(1, xi.p[[i]], delta[[k,i]])
    log.prob <- min(1, log.lik(xi.p,omega.arg=omega.mcmc[k-1]) - log.lik(xi.c,omega.arg=omega.mcmc[k-1]))
    if (log(runif(1)) < log.prob) {
      xi.c <- xi.p
      accepted.n[[i]] <- accepted.n[[i]] + 1
    }
    
    if(k<M){
      # adaptative variance
      acceptance.rate[[i]] <- accepted.n[[i]] / k
      if ((acceptance.rate[[i]] < acceptance.target * (1 - .1))||(acceptance.rate[[i]] > acceptance.target * (1 + .1))) {
        delta[k+1,i] <- delta[[k,i]] * (1 - delta.ar)
      } else{
        delta[k+1,i] <- delta[[k,i]]
      }
    }
  }
  xi.mcmc[k, ] <- xi.c
  }
  
  f.k=f(xi.c)
  #Etape calcul des stats exhaustives
  S1=mean((Y-f.k)^2)
  #Etape approximation stochastique
  s1[k]<-s1[k-1]+alpha[k]*(S1-s1[k-1])
  
  #Etape de maximisation 
  omega.mcmc[k]=sqrt(s1[k])
  
}
plot(omega.mcmc,type='l',col='blue',main=paste("nb d'iterations du MCMC = ",J))
abline(h=omega,col='red')
}
```


# Ajout de l'estimation des autres parametres() : EM + omega + psi 


```{r,fig.height=8,fig.width=11}
n=500
M <- 200
J<-4
delta <- matrix(.5,ncol=n,nrow=M,byrow=T)
delta.ar <- 0.1
omega.mcmc<-rep(0,M)
omega.mcmc[1]=0.5

psi.mcmc<-rep(0,M)
psi.mcmc[1]=0.5

gamma.mcmc<-rep(0,M)
gamma.mcmc[1]=0.5
  
s1<-rep(0,M)
s2<-rep(0,M)
s3<-rep(0,M)
s4<-rep(0,M)


D.alpha<-90
alpha<-rep(1,M)
alpha[D.alpha:M]=1/((1:(M-(D.alpha-1)))^0.8)

xi.mcmc <- matrix(nrow = M, ncol = n)
xi.c <- rep(0,n)
xi.mcmc[1,]<-rxi() #PB d'initialisation car si le premier xi.mcmc[1, ]= 0 alors pas possible de calculer les statistiques, du coup j'ai essayer rxi() ? 
accepted.n <- rep(0, n)
acceptance.rate <- rep(0, n)
acceptance.target <- .23


for (k in 2:M) {
  # Etape MCMC 
  for(j in 1:J){
  for (i in 1:n) {
    xi.p <- xi.c
    xi.p[[i]] <- rnorm(1, xi.p[[i]], delta[[k,i]])
    log.prob <- min(1, log.lik(xi.p,omega.arg=omega.mcmc[k-1],psi.arg=psi.mcmc[k-1],gamma.arg = gamma.mcmc[k-1]) - log.lik(xi.c,omega.arg=omega.mcmc[k-1],psi.arg = psi.mcmc[k-1],gamma.arg = gamma.mcmc[k-1]))
    if (log(runif(1)) < log.prob) {
      xi.c <- xi.p
      accepted.n[[i]] <- accepted.n[[i]] + 1
    }
    
    if(k<M){
      # adaptative variance
      acceptance.rate[[i]] <- accepted.n[[i]] / k
      if ((acceptance.rate[[i]] < acceptance.target * (1 - .1))||(acceptance.rate[[i]] > acceptance.target * (1 + .1))) {
        delta[k+1,i] <- delta[[k,i]] * (1 - delta.ar)
      } else{
        delta[k+1,i] <- delta[[k,i]]
      }
    }
  }
  xi.mcmc[k, ] <- xi.c
  }
  f.k=f(xi.c)
  
  #Etape calcul des stats exhaustives
  S1=mean((Y-f.k)^2)
  S2=sum(xi.mcmc[k-1,]*xi.mcmc[k,]) #PROBLEME pour k autour de 30, psi devient > 1 et pas possible avec le calcul de vraisemblance
  S3=sum(xi.mcmc[k-1,]*xi.mcmc[k-1,])
  S4=sum(xi.mcmc[k, ]*xi.mcmc[k, ])
  
  #Etape approximation stochastique
  s1[k]<-s1[k-1]+alpha[k]*(S1-s1[k-1])
  s2[k]<-s2[k-1]+alpha[k]*(S2-s2[k-1])
  s3[k]<-s3[k-1]+alpha[k]*(S3-s3[k-1])
  s4[k]<-s4[k-1]+alpha[k]*(S4-s4[k-1])

  
  #Etape de maximisation 
  omega.mcmc[k]=sqrt(s1[k])
  psi.mcmc[k]=s2[k]/s3[k]
  gamma.mcmc[k]=sqrt((1/n)*(psi.mcmc[k]^2*s3[k]-2*psi.mcmc[k]*s2[k]+s4[k]))
  
}

plot(xi, type = "l", col = "blue",main="xi")
lines(xi.mcmc[nrow(xi.mcmc), ], type = "l", col = "red")

plot(Y, type = "l", col = "blue",main="Y")
lines(f(xi.mcmc[nrow(xi.mcmc), ]), type = "l", col = "red")

par(mfrow=c(2,2))

plot(omega.mcmc,type='l',col='blue',main="Omega",ylim=c(0,0.5))
abline(h=omega,col='red')

plot(psi.mcmc,type='l',col='blue',main="Psi")
abline(h=psi,col='red')

plot(gamma.mcmc,type='l',col='blue',main="gamma")
abline(h=gamma,col='red')


```




