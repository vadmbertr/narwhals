---
title: "Effet des perturbations humaines sur l'alimentation des narvals"
output:
  bookdown::pdf_document2:
    toc: true
    toc_depth: 3
toc-title: "Sommaire"
urlcolor: blue
linkcolor: blue
header-includes:
    \usepackage{amssymb}
    \usepackage{bbm}
    \usepackage{dirtytalk}
    \usepackage{float}
    \makeatletter\renewcommand*{\fps@figure}{H}\makeatother
---

```{r setup, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE,
                      comment = NA, warning = FALSE,
                      message = FALSE)
knitr::opts_chunk$set(fig.width = 6, fig.height = 3, fig.align = "center")
```

```{r}
library(ggplot2)
library(kableExtra)
library(latex2exp)
library(mvtnorm)
library(patchwork)
library(reshape2)
library(splines)

source("../../R/1_buzzing/utils/biexp.R")
source("../../R/1_buzzing/utils/monte_carlo_conf_int.R")

set.seed(15)
```

\newpage

\qquad Les narvals sont des baleines vivant toute l'année au Groenland.
Le réchauffement climatique favorise le recul des glaces sur le territoire groenlandais et ses côtes.
Cela ouvre la porte au développement d'activités humaines au Groenland, et notamment les activités minières.
Les biologistes se questionnent sur les effets potentiels engendrés sur les comportements des narvals.

\qquad Afin d'anticiper ces possibles changements de comportements une étude a été conduite pendant plusieurs mois en 2018.
Dans ce cadre, 8 narvals ont été équipées de capteurs permettant d'enregistrer leur profondeur de plongée, leur localisation et les sons qu'elles émettent.
Les baleines ont été laissées libres de toutes perturbations pendant plusieurs jours avant d'y être exposées.
Les perturbations ont pris la forme de coups de fusil tirés dans l'eau depuis un bateau afin d'imiter les ondes émises par des activités minières.

\qquad Lorsqu'elles se nourissent, les narvals émettent des sons spécifiques appelés \say{buzz}.
À partir des sons collectés il est donc possible de déterminer quand ces baleines sont en train de manger.
La distance séparant les baleines du bateau émettant une perturbation peut-elle être calculée grâce aux puces GPS placées sur les narvals.
Ainsi, nous pouvons tenter de modéliser l'effet de l'exposition des perturbations humaines sur la capacité des narvals à se nourrir.

# Modélisation de l'effet de l'exposition sur le taux d'émission

## Taux d'émission de buzz sans exposition

\qquad Etant donné que nous voulons modéliser un taux, la régression de Poisson est l'outil tout indiqué.
On suppose que le taux d'émission de buzz $Y$, dépendant d'un ensemble de variables $X$, suit une loi de Poisson de paramètre $\lambda$, et on a que $\mathbb{E}(Y \vert X) = \lambda$.
La régression de Poisson permet de modéliser le $log$ de $\lambda$ par une combinaison linéaire des variables $X$ :
$$log(\lambda) = \beta_0 + X \beta$$
Les variables $X$ utilisées dans le modèle sont détaillées dans la suite de cette section.
Il n'existe pas d'expression explicite de l'estimateur du maximum de vraisemblance des paramètres $\beta$, cependant maximiser cette vraisemblance est un problème d'optimisation convexe qui peut être résolu numériquement.

\qquad Les données que nous utilisons correspondent à plusieurs individus, nous avons donc plusieurs observations par individus et celles-ci ne sont pas indépendantes.
Pour palier ce défaut de modélisation et tenir compte de la spécifité des individus, nous avons ajouté des effets aléatoires $b_i$ au modèle : $$log(\lambda_i) = \beta_0 + b_i + X_i \beta$$
où $i$ dénote les observations de l'individu $i$ et $b_i \sim \mathcal{N}(O, \sigma_i^2)$, $\sigma_i^2$ étant la variance intra-individu.

\qquad Pour se nourrir, les narvals doivent plonger profondément (plusieurs centaines de mètres), alors que le reste du temps elles restent \say{proche} (quelques dizaines de mètres) de la surface.
Il faut donc inclure au modèle la profondeur à laquelle se trouvent les baleines quand elles émettent ou non des buzz.
La relation entre l'émission de buzz et la profondeur n'étant pas linéaire, la profondeur a été remplacée par une spline cubique naturelle ayant pour noeuds les quantiles $1/3$ et $2/3$.
Nous pouvons expliciter un peu plus l'expression précédente du modèle :
$$log(\lambda_i) = \beta_0 + b_i + spline(Depth_i) \beta_D$$

\qquad Passer par l'estimateur du maximum de vraisemblance nécessite que les observations $Y_{ij}$ soient indépendantes.
Or, l'émission d'un buzz à un instant $t$ est corrélé à l'émission ou non de buzz aux instants précédents ; cet effet mémoire doit donc être intégré au modèle pour rendre les $Y_{ij}$ indépendants.
Pour cela nous introduisons $K$ variables binaires d'auto-régression codant l'émission d'un buzz aux l'instants $t - k,\ k \in \{1, ..., K\}$.
Le modèle résultant s'écrit alors :
$$log(\lambda_i(t)) = \beta_0 + b_i + spline(Depth_i(t)) \beta_D + \sum_{k=1}^K \alpha_k Y_i(t-k)$$
Cette approche demande de fixer une mémoire maximale, et ainsi la valeur de $K$.
Pour choisir la mémoire maximale optimale, nous avons fait varier $K$ et utilisé le BIC comme mesure de la qualité des différents modèles correspondants ; nous choisissons la mémoire maximale $K_{opt}$ du modèle minimisant ce critère.
Pour éviter de parcourir tout l'ensemble $\{K_{min}, ..., K_{max}\}$, nous avons utilisé une démarche permettant de restreindre le pas de recherche au fur et à mesure que l'on s'approche de $K_{opt}$ :

1. $from.k = K_{min}\ ;\ to.k = K_{max}$
2. Tant que $(to.k - from.k > 2)$ :
   1. Pour $K_i = from.k + (i-1) * \lfloor\frac{to.k-from.k}{M-1}\rceil,\ i \in \{1, ..., M\}$ :
      1. ajustement d'un modèle avec $K_i$ éléments mémoire
      2. calcul du BIC
   2. $i_{opt} = argmin\ BIC_i$
   3. $K_{opt} = K_{i_{opt}}$
   4. $from.k = K_{i_{opt}-1}\ ;\ to.k = K_{i_{opt}+1}$

\qquad Le nombre de composants auto-régressifs pouvant être grand, nous avons utilisé une régression bi-exponentielle double permettant de lier le décalage mémoire et le coefficient associé :
$$BiExp(lag) = A_1 e^{-e^{lrc_1} lag} + A_2 e^{-e^{lrc_2} lag}$$
Cela permet de réduire le nombre de coefficients de $K_{opt}$ à $4$, ce qui est doublement bénéfique : le temps d'ajustement des modèles est grandement réduit et lors de la construction des intervalles de confiance de nos coefficients, l'accumulation des variances est limitée.

## Effet de l'exposition

\qquad Le niveau d'exposition aux perturbations est représenté par l'inverse de la distance séparant la baleine du bateau quand un coup de feu est tiré.
De même que pour la profondeur, la non-linéarité de la relation entre le niveau d'exposition et le taux d'émission de buzz est représentée par l'utilisation d'une spline cubique naturelle dont les noeuds sont les quantiles $1/3$ et $2/3$ des niveaux d'exposition.

\qquad Afin d'observer l'effet de l'exposition aux perturbations par rapport à l'émission de buzz sans perturbation, nous ajoutons un terme d'\say{offset}.
Cet offset est calculé à partir des coefficients $\hat{\beta_D},\ \hat{A_1},\ \hat{lrc_1},\ \hat{A_2},\ \hat{lrc_2}$ estimés sans perturbation :
$$offset_i(t) = spline(Depth_i(t)) \hat{\beta_D} + \sum_{k=1}^{K_{opt}} (\hat{A_1} e^{-e^{\hat{lrc_1}} k} + \hat{A_2} e^{-e^{\hat{lrc_2}} k}) Y_i(t-k)$$

\qquad Le modèle incluant l'exposition s'écrit donc :
$$log(\lambda_i(t)) = offset_i(t) + \beta_0 + b_i + spline(Expo_i(t)) \beta_E$$
Et les paramètres estimés $\hat{\beta_E}$ permettront d'interpréter l'effet de l'exposition par rapport à des conditions de stress normales.

## Construction d'intervalles de confiance

\qquad Pour se rassurer quant à l'interprétabilité des résultats obtenus il est important de construire les intervalles de confiance des estimations des coefficients associés à l'exposition aux perturbations.
L'approche classique de calcul des intervalles de confiance se basant sur la seule variance estimée des coefficients d'exposition donnerait ici des résultats incorrects, la variance des coefficients de profondeur et d'auto-régression ne serait alors pas prise en compte car tuée par l'utilisation de l'offset.
Nous avons donc utilisée une approche Monte-Carlo lors de laquelle nous répétons $M = 1000$ fois l'ajustement du modèle incluant l'exposition en tirant aléatoirement les coefficients $\hat{\beta_D},\ \hat{A_1},\ \hat{lrc_1},\ \hat{A_2},\ \hat{lrc_2}$ selon leur moyenne et leur variance.
Les $1000$ ajustements obtenus nous fournissent ainsi un échantillon pour chacun des coefficients d'exposition et nous construisons leur intervalle de confiance via les quantiles empiriques de leur distribution.

# Résultats

## Note sur le temps d'ajustement des modèles

```{r}
glm.profiling <- as.data.frame(readRDS("../../data/1_buzzing/glm_buzz_depth_maxlag_profiling/profiling.rds"))
glm.profiling$maxlag <- as.numeric(rownames(glm.profiling))

glmer.profiling <- as.data.frame(readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag_profiling/profiling.rds"))
glmer.profiling$maxlag <- as.numeric(rownames(glmer.profiling))
```

\qquad Le temps d'ajustement des modèles, et en particulier des modèles mixtes, augmente fortement lorsque que le nombre de paramètres à ajuster augmentent. \newline
Comme nous pouvons le voir sur la figure \@ref(fig:glm-time) cette augmentation est linéaire pour les modèles classiques, alors que pour les modèles mixtes celle-ci est quadratique.

```{r glm-time, fig.width = 8, fig.cap = "Temps d'ajustement (en secondes) des modèles en fonction de la mémoire maximum."}
g1 <- ggplot(glm.profiling, aes(x = maxlag, y = total_time, group = 1)) +
  geom_line() +
  geom_point() +
  geom_function(fun = function(x) { x }, linetype = "dashed") +
  labs(x = "Composants mémoire",
       y = "Temps d'ajustement [secondes]",
       caption = "Modèles classiques") +
  theme(plot.margin = margin(0, 0, 0, 0, "pt"))

g2 <- ggplot(glmer.profiling, aes(x = maxlag, y = total_time, group = 1)) +
  geom_line() +
  geom_point() +
  geom_function(fun = function(x) { x^2.5 }, linetype = "dashed") +
  labs(x = "Composants mémoire",
       y = "Temps d'ajustement [secondes]",
       caption = "Modèles mixtes") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 1, "pt"))

g1 + g2
```

## Taux d'émission de buzz sans exposition

### Recherche de la mémoire optimale

```{r}
maxlag.bic <- readRDS("../../data/1_buzzing/glm_buzz_depth_maxlag/maxlag.bic.rds")
maxlag.opt <- as.integer(maxlag.bic[which.min(maxlag.bic[, 2]), 1])
maxlag.glmer.bic <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/maxlag.bic.rds")
maxlag.glmer.opt <- as.integer(maxlag.glmer.bic[which.min(maxlag.glmer.bic[, 2]), 1])
```

\qquad Le temps d'ajustement des modèles mixtes étant nettement plus important que ceux des modèles sans effets aléatoires, nous avons dans un premier temps exclu ces effets du modèle sans exposition pour estimer la mémoire optimale.
Nous avons choisi pour la recherche $K_{min} = 1,\ K_{max} = 300,\ M = 10$
Nous obtenons une mémoire optimale de `r maxlag.opt` secondes.
La figure \@ref(fig:maxlag-bic) permet de voir que cet optimal semble bien correspondre à un minimum global.

```{r maxlag-bic, fig.width = 8, fig.cap = "BIC en fonction de la mémoire maximum."}
g1 <- ggplot(maxlag.bic, aes(x = maxlag, y = BIC)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = maxlag.opt, col = "blue", lty = 2) +
  labs(x = "Mémoire maximum [secondes]", caption = "Modèles classiques")
g2 <- ggplot(maxlag.glmer.bic, aes(x = maxlag, y = BIC)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = maxlag.glmer.opt, col = "blue", lty = 2) +
  labs(x = "Mémoire maximum [secondes]", caption = "Modèles mixtes")

g1 + g2
```

Cela nous a permis de restreindre tout de suite l'ensemble de recherche initial à $\{30, ..., 90\}$ quand nous avons considéré le modèle incluant les effets aléatoires.
De même que précédemment, nous obtenons une mémoire optimale de `r maxlag.glmer.opt` secondes et la figure \@ref(fig:plot-glm-bic) nous indique qu'il s'agit bien d'un optimum global.

### Régression double bi-exponentielle sur les coefficients autorégressifs

\qquad La figure \@ref(fig:biexp-AR) permet de comparer la régression double bi-exponentielle et les composantes de la mémoire ajustées pour un décalage maximum de `r maxlag.opt`.
Nous pouvons constater que l'ajustement par la double bi-exponentielle est très fidèle aux `r maxlag.opt` coefficients initiaux.

```{r}
ARcoefs.fit <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/ARcoef.fit.rds")
```

```{r biexp-AR, fig.cap = "Régression bi-exponentielle des coefficients auto-régressifs."}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

Les 4 coefficients obtenus suite à la régression double bi-exponentielle sont présentés dans la table \@ref(tab:coef-biexp-AR).
Nous pouvons noter que leurs erreurs standard sont faibles, ce qui est cohérent avec la validation visuelle de la régression.

```{r}
RegBiExp.coefs <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/ARcoef.RegBiExp.rds")
```

```{r coef-biexp-AR}
df <- data.frame(RegBiExp.coefs[, c("estimate", "std.error", "p.value")])
row.names(df) <- c("$A_1$", "$lrc_1$", "$A_2$", "$lrc_2$")
kable(df,
      col.names = c("moyenne", "erreur standard", "p-valeur"),
      caption = "Coefficients autorégressifs obtenus par régression bi-exponentielle",
      label = "coef-biexp-AR",
      escape = FALSE) %>%
  kable_styling(latex_options = "HOLD_position")
```

### Coefficients de profondeur

\qquad Les coefficients de profondeur du modèle linéaire mixte sans exposition sont proposés table \@ref(tab:coef-glmer-depth).
Interpréter les coefficients associés à des splines étant difficile, nous nous contenterons de relever que seul les pvaleurs de $\beta_{D_2}$ et $\beta_{D_3}$ sont significatives au seuil $\alpha = 5\%$ et que l'erreur standard de $\beta_{D_1}$ semble élevée relativement à sa moyenne.

```{r}
glmer.coefs <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/ARcoef.best.rds")
```

```{r coef-glmer-depth}
df <- data.frame(glmer.coefs[3:5, c("estimate", "std.error", "p.value")])
row.names(df) <- c("$\\beta_{D_1}$", "$\\beta_{D_2}$", "$\\beta_{D_3}$")
kable(df,
      col.names = c("moyenne", "erreur standard", "p-valeur"),
      caption = "Coefficients de profondeur.",
      label = "coef-glmer-depth",
      escape = FALSE) %>%
  kable_styling(latex_options = "HOLD_position")
```

## Effet de l'exposition

\qquad La table \@ref(tab:coef-glmer-expo) expose les coefficients associés à l'exposition du modèle mixte.
De même que pour les coefficients de profondeur, il est compliqué d'interpréter leur valeur.
Aussi, nous préférons nous référer à la lecture de la figure \@ref(fig:mod-expo-rate) sur laquelle nous représentons les estimations du modèle pour le taux d'émission de buzz selon la distance avec le bateau. Il est clair que plus le bateau est loin, plus le taux d'émission est élevé.

```{r}
predFrame <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_pred/predFrame.rds")
predFramePop <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_pred/predFramePop.rds")
```

```{r mod-expo-rate, fig.cap = "Evolution du taux d'émission de buzz selon la distance au bateau."}
ggplot(data = predFrame, aes(x = 1 / X, y = 60 * exp(predBuzz), color = Ind)) +
  geom_line() +
  geom_line(data = predFramePop, aes(x = 1 / X, y = 60 * exp(predBuzzPop)), size = 1.2, color = "black") +
  xlim(0, 50) +
  xlab("Distance avec le bateau (km)") +
  ylab("Taux d'émission de buzz (1/min)") +
  facet_grid(. ~ model)
```

```{r}
glmerAllBuzzDepth.tidy <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/glmerAllBuzzDepth.tidy.rds")
glmerAllBuzzDepth.glance <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/glmerAllBuzzDepth.glance.rds")
acf.plot.data <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/acf.plot.data.rds")
QQ.plot.data <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/QQ.plot.data.rds")
z.plot.data <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/z.plot.data.rds")
```

```{r coef-glmer-expo}
df <- data.frame(glmerAllBuzzDepth.tidy[2:4, c("estimate", "std.error", "p.value")])
row.names(df) <- c("$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("moyenne", "erreur standard", "p-valeur"),
      caption = "Coefficients d'exposition.",
      label = "coef-glmer-expo",
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position"))
```

La figure \@ref(fig:mod-expo-val) présente plusieurs graphiques utiles pour valider visuellement le modèle : nous sommes satisfaits de l'absence de corrélation entre les résidus constatée sur les deux premiers et du comportement gaussien visible sur le dernier.

```{r mod-expo-val, fig.height = 5, fig.cap = "Validation graphique du modèle."}
g1 <- ggplot(data = acf.plot.data, aes(x = lag, y = acf)) +
  geom_col(size = .2) +
  labs(x = "Décalage", y = "Autocorrélation",
       caption = "Autocorrélation des résidus") +
  theme(plot.margin = margin(0, 0, 1, 0, "pt"))

g2 <- ggplot(data = z.plot.data[2:nrow(z.plot.data),], aes(x = Zlow, y = Zupp)) +
  geom_point(size = .25) +
  labs(x = TeX("$Z_{i+1}$"), y = TeX("$Z_{i}$"),
       caption = "Résidu selon le précédent") +
  coord_fixed() +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g3 <- ggplot(QQ.plot.data, aes(x = qunif, y = qZ)) +
  geom_point(size = .5) +
  geom_abline(slope = 1, intercept = 0, size = 1, linetype = "dashed") +
  labs(x = "Quantiles uniformes théoriques ", y = "Quantiles empiriques",
       caption = "Q-Q plot") +
  coord_fixed() +
  theme(plot.margin = margin(0, 0, 0, 0, "pt"))

g1 / (g2 + g3)
```

## Intervalles de confiance

### Coefficients d'exposition

#### Utilisation de lois normales univariées

Dans un premier temps, nous avons considéré que les coefficients autorégressifs et de profondeur suivaient chacun une loi normale centrée sur leur estimation moyenne et avec une variance égale au carré de leur erreur standard.
Nous avons donc 4 lois normales univariées pour les coefficients de la régression double bi-exponentille et 4 autres pour la spline sur la profondeur.

```{r}
B <- 1000
A1 <- rnorm(B, RegBiExp.coefs$estimate[1], RegBiExp.coefs$std.error[1])
lrc1 <- rnorm(B, RegBiExp.coefs$estimate[2], RegBiExp.coefs$std.error[2])
A2 <- rnorm(B, RegBiExp.coefs$estimate[3], RegBiExp.coefs$std.error[3])
lrc2 <- rnorm(B, RegBiExp.coefs$estimate[4], RegBiExp.coefs$std.error[4])
ARcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- BiExp(A1[[b]], lrc1[[b]], A2[[b]], lrc2[[b]], lag = ARcoefs.fit$lag)
  data.frame(lag = ARcoefs.fit$lag, estimate = estimate, b = as.factor(b))
}))

estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
  glmer.coefs$estimate[2:5]
Depthcoefs.fit <- data.frame(depth = -1000:0, estimate = estimate)
d1 <- rnorm(B, glmer.coefs$estimate[2], glmer.coefs$std.error[2])
d2 <- rnorm(B, glmer.coefs$estimate[3], glmer.coefs$std.error[3])
d3 <- rnorm(B, glmer.coefs$estimate[4], glmer.coefs$std.error[4])
d4 <- rnorm(B, glmer.coefs$estimate[5], glmer.coefs$std.error[5])
Depthcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
    c(d1[[b]], d2[[b]], d3[[b]], d4[[b]])
  data.frame(depth = -1000:0, estimate = estimate, b = as.factor(b))
}))
```

Sur la figure \@ref(fig:coef-ar-norm) nous avons représenté les courbes des fonctions double bi-exponentielles ainsi générées.
Nous pouvons voir que leurs allures semblent toujours suivre celle de la régression initiale.

```{r coef-ar-norm, fig.cap = "Variation des coefficients autorégressif selon des lois normales univariées."}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_line(data = ARcoefs.fit.mc, aes(x = lag, y = estimate, group = b), alpha = .1, col = "red") +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

Nous avons fait de même avec les coefficients de profondeur, et nous pouvons remarquer sur la figure \@ref(fig:coef-depth-norm) que cette fois-ci l'allure de certaines courbes s'éloignent sensiblement de l'interpolation moyenne.

```{r coef-depth-norm, fig.cap = "Variation des coefficients de profondeur selon des lois normales univariées."}
ggplot(Depthcoefs.fit) +
  geom_line(data = Depthcoefs.fit.mc, aes(x = depth, y = estimate, group = b), alpha = .1, col = "red") +
  geom_line(aes(x = depth, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Profondeur [mètres]", y = "ns")
```

```{r}
expo.coef <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_par/expo.coef.norm.rds")

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

alpha <- .05
expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

Les intervalles de confiance calculés avec la procédure Monte Carlo sont donnés sur la table \@ref(tab:coef-expo-ci-norm).
Nous avons également affiché les valeurs médianes des intervalles de confiance calculés à chaque répétition sur la base de la variation des coefficients d'exposition uniquement.
Il est flagrant que les intervalles Monte Carlo sont bien plus larges et ne permettent en aucun cas de conclure sur un effet de l'exposition sur le taux d'émission de buzz.

```{r coef-expo-ci-norm}
df <- data.frame(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint))
row.names(df) <- c("$\\beta_0$", "$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("inf", "sup", "inf", "sup"),
      caption = "Intervalles de confiance dans le cas de normales univariées.",
      label = "coef-expo-ci-norm",
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position")) %>%
  add_header_above(c(" " = 1, "Monte Carlo" = 2, "Erreur standard" = 2))
```

La figure \@ref(fig:coef-expo-ci-norm-dist) donne une représentation graphique de ces intervalles (en rouge les "MC" et en bleu les "SE"), ainsi que des distributions des coefficients.

```{r coef-expo-ci-norm-dist, fig.height = 5, fig.cap = "Intervalles de confiance dans le cas de normales univariées."}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_1$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_2$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_3$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

#### Utilisation d'une loi normale multivariée {#mvnorm}

L'une des explications aux très larges intervalles de confiance observés dans la section précédente pourrait être que nous avons accumulé les variances des coefficients sans tenir compte des probables covariances existant entre les coefficients.
Afin de corriger cela nous avons répété l'approche décrite précédemment, mais en tirant les coefficients dans des lois normales multivariées (une pour les coefficients de la régression double bi-exponentielle et une pour les coefficients de la spline) toujours centrées sur les estimations moyennes, mais ayant des matrices de variance-covariance non diagonales.
Dorénavant nous avons donc une loi normale multivariée pour les coefficients de la régression double bi-exponentielle et une autre pour la profondeur, les deux étant de dimension 4.

```{r}
RegBiExp.vcov <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/RegBiExp.vcov.rds")
ARcoefs <- rmvnorm(B, mean = RegBiExp.coefs$estimate, sigma = RegBiExp.vcov,
                   checkSymmetry = FALSE)
ARcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- BiExp(ARcoefs[b, 1], ARcoefs[b, 2], ARcoefs[b, 3], ARcoefs[b, 4],
                    lag = ARcoefs.fit$lag)
  data.frame(lag = ARcoefs.fit$lag, estimate = estimate, b = as.factor(b))
}))

estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
  glmer.coefs$estimate[2:5]
Depthcoefs.fit <- data.frame(depth = -1000:0, estimate = estimate)
Depth.vcov <- as.matrix(readRDS("../../data/1_buzzing/glmer_buzz_ARDepth/glmERBuzzARDepth.vcov.rds"))[2:5, 2:5]
Depthcoefs <- rmvnorm(B, mean = glmer.coefs$estimate[2:5], sigma = Depth.vcov,
                      checkSymmetry = FALSE)
Depthcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
    c(Depthcoefs[b, 1], Depthcoefs[b, 2], Depthcoefs[b, 3], Depthcoefs[b, 4])
  data.frame(depth = -1000:0, estimate = estimate, b = as.factor(b))
}))
```

La figure \@ref(fig:coef-ar-mvnorm) montre que la régression biexponentielle initiale est encore plus fidèlement suivie qu'auparavant.

```{r coef-ar-mvnorm, fig.cap = "Variation des coefficients autorégressifs selon une loi normale multivariée."}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_line(data = ARcoefs.fit.mc, aes(x = lag, y = estimate, group = b), alpha = .1, col = "red") +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

Et surtout, comme nous pouvons le voir sur la figure \@ref(fig:coef-depth-mvnorm), il en va de même pour la profondeur, alors que précédemment les tirages donnaient des courbes fortement éloignées de celle attendue.

```{r coef-depth-mvnorm, fig.cap = "Variation des coefficients de profondeur selon une loi normale multivariée."}
ggplot(Depthcoefs.fit) +
  geom_line(data = Depthcoefs.fit.mc, aes(x = depth, y = estimate, group = b), alpha = .1, col = "red") +
  geom_line(aes(x = depth, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Profondeur [mètres]", y = "ns")
```

```{r}
expo.coef <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_par/expo.coef.mvnorm.biexp.rds")

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

Sur la table \@ref(tab:coef-expo-ci-mvnorm) nous pouvons constater que les intervalles de confiance estimés en utilisant des lois normales multivariées sont nettement plus petits et peuvent conduire à conclure sur un effet de l'exposition sur le taux d'émission de buzz.

```{r coef-expo-ci-mvnorm}
df <- data.frame(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint))
row.names(df) <- c("$\\beta_0$", "$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("inf", "sup", "inf", "sup"),
      caption = "Intervalles de confiance dans le cas de normales multivariées.",
      label = "coef-expo-ci-mvnorm",
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position")) %>%
  add_header_above(c(" " = 1, "Monte Carlo" = 2, "Erreur standard" = 2))
```

Nous pouvons également voir sur la figure \@ref(fig:coef-expo-ci-mvnorm-dist) que les distributions semblent normales, contrairement à celles observées avec les lois univariées.

```{r coef-expo-ci-mvnorm-dist, fig.height = 5, fig.cap = "Intervalles de confiance dans le cas de normales multivariées."}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_1$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_2$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_3$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

#### Variance-covariance des coefficients autorégressifs

Bien que plus intéressante, la procédure que nous avons mise en place se base sur la matrice de variance-covariance des coefficients de la régression double bi-exponentielle, ce qui signifie que nous ne captons pas directement la variabilité du phénomène autorégressif mais plutôt celle de la régression double bi-exponentielle.
Pour palier cette approximation nous avons tenté d'estimer la matrice de variance-covariance des coefficients autorégressifs, à nouveau par une procédure Monte Carlo.
Cette fois-ci nous répétons 1000 fois le tirage des 60 coefficients de mémoire à partir d'une loi normale multivariée et à chaque fois nous ajustons une régression double bi-exponentielle sur les 60 coefficients tirés ; finalement nous pouvons obtenir les estimations moyennes des coefficients de la double bi-exponentielle, ainsi que la matrice de variance-covariance associée.
Nous reprenons enfin la procédure Monte Carlo employée dans la section précédente avec le vecteur de moyennes et la matrice de variance-covariance obtenus.

```{r}
biexp.coef.cov <- readRDS("../../data/1_buzzing/glmer_biexp_AR_mc/biexp.coef.cov.rds")
biexp.coef.estimate <- readRDS("../../data/1_buzzing/glmer_biexp_AR_mc/biexp.coef.estimate.rds")
ARcoefs <- rmvnorm(B, mean = apply(biexp.coef.estimate, 2, mean),
                   sigma = biexp.coef.cov,
                   checkSymmetry = FALSE)
ARcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- BiExp(ARcoefs[b, 1], ARcoefs[b, 3], ARcoefs[b, 2], ARcoefs[b, 4],
                    lag = ARcoefs.fit$lag)
  data.frame(lag = ARcoefs.fit$lag, estimate = estimate, b = as.factor(b))
}))
```

Nous pouvons contrôler sur la figure \@ref(fig:coef-ar-mvnorm-mc) que les régressions double bi-exponentielles obtenues restent cohérentes.

```{r coef-ar-mvnorm-mc, fig.cap = "Variation des coefficients autorégressif selon une loi normale multivariée estimée par Monte Carlo."}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_line(data = ARcoefs.fit.mc, aes(x = lag, y = estimate, group = b), alpha = .1, col = "red") +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

```{r}
expo.coef <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_par/expo.coef.mvnorm.mc.rds")

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

La table \@ref(tab:coef-expo-ci-mvnorm-mc) et la figure \@ref(fig:coef-expo-ci-mvnorm-dist-mc) permettent de vérifier que bien que les intervalles calculés ainsi sont légèrement plus grands que les précédents, ils permettent toujours d'interpréter les coefficients d'exposition ajustés par le modèle.

```{r coef-expo-ci-mvnorm-mc}
df <- data.frame(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint))
row.names(df) <- c("$\\beta_0$", "$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("inf", "sup", "inf", "sup"),
      caption = "Intervalles de confiance dans le cas d'une normale multivariée estimée par Monte Carlo.",
      label = "coef-expo-ci-mvnorm-mc",
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position")) %>%
  add_header_above(c(" " = 1, "Monte Carlo" = 2, "Erreur standard" = 2))
```

```{r coef-expo-ci-mvnorm-dist-mc, fig.height = 5, fig.cap = "Intervalles de confiance dans le cas d'une normale multivariée estimée par Monte Carlo."}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_1$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_2$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_3$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

#### Sans passer par la régression biexponentielle

L'intérêt de la régression biexponentielle était de :

1. réduire le temps d'ajustement des modèles linéaires,
2. éviter d'accumuler les variances des 60 coefficients de mémoire.

En fixant les coefficients autorégressifs, avoir 4 ou 60 coefficients pour la mémoire n'importe plus ; et en utilisant une loi normale multivariée, nous devrions également ne plus accumuler directement les variances des coefficients.
Ainsi, nous avons tenté de nous passer de la régression double bi-exponentielle, et donc de tirer les 60 coefficients mémoire et les 4 coefficients de profondeur directement dans une seule loi normale multivariée.

```{r}
expo.coef <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_par/expo.coef.mvnorm.rds")

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

Nous pouvons voir sur la table \@ref(tab:coef-expo-ci-mvnorm-full) et la figure \@ref(fig:coef-expo-ci-mvnorm-dist-full) qu'avec cette approche plus directe, les intervalles de confiance sont quasiment identiques à ceux obtenus dans la section \@ref(mvnorm), et même plus petit pour l'intercept.

```{r coef-expo-ci-mvnorm-full}
df <- data.frame(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint))
row.names(df) <- c("$\\beta_0$", "$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("inf", "sup", "inf", "sup"),
      caption = "Intervalles de confiance dans le cas d'une loi normale multivariée sans double bi-exponentielle.",
      label = "coef-expo-ci-mvnorm-full",
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position")) %>%
  add_header_above(c(" " = 1, "Monte Carlo" = 2, "Erreur standard" = 2))
```

```{r coef-expo-ci-mvnorm-dist-full, fig.height = 5, fig.cap = "Intervalles de confiance dans le cas d'une loi normale multivariée sans double bi-exponentielle."}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_1$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_2$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_3$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

### Pourcentage du taux normal d'émission de buzz

\qquad Il est rassurant de voir que les intervalles de confiance des coefficients d'exposition obtenus par Monte Carlo restent raisonnablement petits, cependant comme évoqué précédemment, il n'est pas possible de lier une augmentation ou une diminution du taux d'émission de buzz en fonction de la distance avec le bateau à partir de leur valeur.
C'est pourquoi nous avions représenté graphiquement cette évolution sur la figure \@ref(fig:mod-expo-rate), mais cette visualisation ne proposait pas d'intervalle de confiance ou de bande de prédiction.

```{r}
ChangePop <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_pred/ChangePop.rds")
```

```{r mod-expo-rate-per, fig.cap = "Pourcentage du taux normal d'émission de buzz selon la distance au bateau."}
ggplot(data = ChangePop, aes(x = 1 / X, y = change, color = model)) +
  geom_line() +
  geom_ribbon(aes(ymin = change - CI, ymax = change + CI, fill = model), alpha = 0.5, linetype = 0) +
  xlim(0, 40) +
  xlab("Distance avec le bateau (km)") +
  ylab("Pourcentage du taux normal d'émission") +
  theme(legend.position = "top", legend.title = element_blank())
```
