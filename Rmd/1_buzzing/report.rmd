---
title: "Effet des perturbations humaines sur l'alimentation des narvals"
author: "Yanis BEN BELGACEM, Vadim BERTRAND, Alicia LORANDI, Angélique SAILLET"
output:
  bookdown::pdf_document2:
    toc: true
    toc_depth: 3
toc-title: "Sommaire"
urlcolor: blue
linkcolor: blue
header-includes:
    \usepackage{algpseudocode}
    \usepackage{amsmath}
    \usepackage{amssymb}
    \usepackage{bbm}
    \usepackage{dirtytalk}
    \usepackage{float}
    \usepackage{mathtools}
    \usepackage{xcolor}
    \makeatletter\renewcommand*{\fps@figure}{H}\makeatother
---

```{r setup, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE,
                      comment = NA, warning = FALSE,
                      message = FALSE)
knitr::opts_chunk$set(fig.width = 6, fig.height = 3, fig.align = "center")
```

```{r}
library(ggplot2)
library(kableExtra)
library(latex2exp)
library(mvtnorm)
library(patchwork)
library(reshape2)
library(splines)

source("../../R/1_buzzing/utils/biexp.R")
source("../../R/1_buzzing/utils/monte_carlo_conf_int.R")

set.seed(15)
```

\newpage

\qquad Les narvals sont des baleines vivant toute l'année au Groenland.
Le réchauffement climatique favorise le recul des glaces sur le territoire groenlandais et ses côtes.
Cela ouvre la porte au développement d'activités humaines au Groenland, et notamment des activités minières.
Les biologistes de l'Institut groenlandais des ressources naturelles se questionnent sur les effets potentiels engendrés par la présence humaine sur les comportements des narvals.

\qquad Afin d'anticiper ces possibles modifications de comportements une étude a été conduite pendant plusieurs mois en 2018.
Dans ce cadre, 8 narvals ont été équipées de capteurs permettant d'enregistrer leur profondeur de plongée, leur localisation et les sons qu'elles émettent.
Les baleines ont été laissées libres de toutes perturbations pendant plusieurs jours avant d'y être exposées.
Les perturbations ont pris la forme de coups de fusil tirés dans l'eau depuis un bateau afin d'imiter les ondes émises par des activités minières.

\qquad Lorsqu'elles se nourissent, les narvals émettent des sons spécifiques appelés \say{buzz}.
À partir des sons collectés il est donc possible de déterminer quand ces baleines sont en train de manger.
La distance séparant les baleines du bateau émettant une perturbation peut être calculée grâce aux puces GPS placées sur les narvals.
Ainsi, nous pouvons modéliser l'effet de l'exposition des perturbations humaines sur l'émission de buzz des narvals et donc indirectement sur leur alimentation.

# Modélisation de l'effet de l'exposition sur le taux d'émission

## Processus de Poisson

\qquad Les données sont collectées toutes les secondes, ainsi nous disposons des temps de collecte $T_j$ et $T_{j+1} = T_j + \Delta$ avec $T_0 = 0$ et $\Delta = 1\ \text{seconde}$.
On peut considérer $N(t)$, le nombre de buzz émis entre le début de la collecte et un instant $t$, comme un processus stochastique pour lequel $N(0) = 0$ et donnant $N(b) - N(a)$ le nombre de buzz émis dans l'intervalle $]a, b]$. \newline
Les processus de comptage sont classiquement représentés par un processus de Poisson dont les accroissements sont indépendants et suivent une loi de Poisson : $N(t + \Delta) - N(t) \sim Pois$.
Dans le cas où l'intensité $\lambda$ du processus dépend de $t$, on parle de processus non-homogène et :
$$N(t + \Delta) - N(t) \sim Pois(\int_t^{t + \Delta} \lambda(u)du)$$
On a donc que :
$$\mathbb{P}(N(t + \Delta) - N(t) = k) = e^{-\int_t^{t + \Delta} \lambda(u)du} \frac{(\int_t^{t + \Delta} \lambda(u)du)^k}{k!}$$
En utilisant le développement limité de l'exponentielle et en considérant $\lambda(t)$ constante sur $]t, t + \Delta]$ on obtient :
\begin{align*}
    \mathbb{P}(N(t + \Delta) - N(t) = 0) &= 1 - \lambda(t) \Delta + o(\Delta) \\
    \mathbb{P}(N(t + \Delta) - N(t) = 1) &= \lambda(t) \Delta + o(\Delta) \\
    \mathbb{P}(N(t + \Delta) - N(t) \geq 2) &= o(\Delta)
\end{align*}
Ainsi, si $\Delta$ est suffisamment petit (de l'ordre de la seconde par exemple), $o(\Delta)$ est négligeable et le processus $Y(t) \vcentcolon = N(t + \Delta) - N(t)$ prend uniquement comme valeurs $0$ ou $1$.
On peut alors ramener notre processus de comptage à un processus de Bernoulli : $Y(t) \sim \mathcal{B}(\lambda(t) \Delta)$, ce qui implique :
$$\mathbb{E}(Y(t)) = \mathbb{P}(Y(t) = 1) = \lambda(t) \Delta \underset{\Delta = 1}{=} \lambda(t)$$

## Modèle linéaire généralisé

\qquad Nous cherchons à estimer le lien entre l'intensité d'émission de buzz et plusieurs covariables, dont le niveau d'exposition aux perturbations.
Nous avons vu dans la section précédente que les variables aléatoires $Y(t)$ de notre processus de comptage sont à valeurs dans ${0, 1}$ et que $\mathbb{P}(Y(t) = 1) = \lambda(t)$.
En se plaçant dans le cadre des modèles linéaires généralisés (GLM) il est donc possible d'exprimer la probabilité $\lambda(t)$ que $Y(t) = 1$ selon un vecteur de covariables $Z(t)$ (détaillées dans la suite de cette section) en utilisant le logarithme comme fonction de lien :
$$log(\lambda(t)) = \beta_0 + Z(t)^T \beta_Z$$
avec $\beta_Z$ le vecteur de paramètres associés au vecteur $Z(t)$.

### Effet de la profondeur

\qquad Pour se nourrir, les narvals doivent plonger profondément (plusieurs centaines de mètres), alors que le reste du temps elles restent \say{proches} (quelques dizaines de mètres) de la surface.
Il faut donc inclure au modèle la covariable de profondeur à laquelle se trouvent les baleines quand elles émettent ou non des buzz.
La relation entre l'émission de buzz et la profondeur n'étant pas linéaire, la profondeur a été remplacée par une spline cubique naturelle ayant pour noeuds les quantiles $1/3$ et $2/3$.

### Effet de l'exposition

\qquad Le niveau d'exposition aux perturbations est représenté par l'inverse de la distance séparant la baleine du bateau quand un coup de feu est tiré.
De même que pour la profondeur, la non-linéarité de la relation entre le niveau d'exposition et le taux d'émission de buzz est représentée par l'utilisation d'une spline cubique naturelle dont les noeuds sont les quantiles $1/3$ et $2/3$ des niveaux d'exposition.

## Non-indépendance des observations

\qquad L'utilisation d'un processus de Poisson pour modéliser nos données de comptage implique l'indépendance des observations $Y(t)$.
En pratique ce n'est pas le cas, aussi il faut modifier le modèle défini précédemment pour tenter de compenser cette absence d'indépendance.

### Utilisation de modèles mixtes

\qquad Les données que nous utilisons correspondent à plusieurs individus, nous avons donc plusieurs observations par individu et celles-ci ne sont pas indépendantes.
Pour palier ce défaut de modélisation et tenir compte de la spécificité des individus, nous utilisons des modèles mixtes en ajoutant un effet aléatoire $b_i$ sur l'ordonnée à l'origine :
$$log(\lambda_i(t)) = \beta_0 + \textcolor{blue}{b_i} + spline(D_i(t)) \beta_D + spline(E_i(t)) \beta_E$$
où $i$ dénote l'individu $i$ et $b_i \sim \mathcal{N}(0, \sigma^2)$ l'effet aléatoire sur cet l'individu, $\sigma^2$ étant la variance inter-individuelle.

### Caractère autorégressif du processus

\qquad De plus, l'émission d'un buzz à un instant $t$ est corrélé à l'émission ou non de buzz aux instants précédents ; cet effet mémoire doit donc être intégré au modèle pour tenir compte de la dépendance des $Y_{i}(t)$.
Pour cela nous introduisons $K$ variables binaires d'autorégression codant l'émission d'un buzz aux l'instants $t - k,\ k \in \{1, ..., K\}$.
Le modèle résultant s'écrit alors :
$$log(\lambda_i(t)) = \beta_0 + b_i + spline(D_i(t)) \beta_D + \textcolor{blue}{\sum_{k=1}^K \alpha_k Y_i(t-k)} + spline(E_i(t)) \beta_E$$
Cette approche demande de fixer une mémoire maximale, et ainsi la valeur de $K$.
Pour choisir la mémoire maximale optimale, nous avons fait varier $K$ et utilisé le BIC comme mesure de la qualité des différents modèles correspondants sans inclure l'effet de l'exposition :
$$log(\lambda_i(t)) = \beta_0 + b_i + spline(D_i(t)) \beta_D + \sum_{k=1}^K \alpha_k Y_i(t-k)$$
Nous choisissons la mémoire maximale $K_{opt}$ du modèle minimisant ce critère.
Pour éviter de parcourir tout l'ensemble $\{K_{min}, ..., K_{max}\}$, nous avons utilisé une démarche permettant de restreindre le pas de recherche au fur et à mesure que l'on s'approche de $K_{opt}$ :

\begin{algorithmic}
\State $from_k \gets K_{min};\ to_k \gets K_{max}$ \Comment{Bornes de l'intervalle de recherche}
\State $M \gets 10$ \Comment{Nombre d'éléments évalués dans l'intervalle}
\While{$(to_k - from_k > 2)$} \Comment{On s'arrête quand on évalué l'ensemble du voisinage du minimum}
    \State $K \gets []$
    \State $BIC \gets []$
    \For{$i \in \{1, ..., M\}$}
        \State $K[i] \gets from_k + (i - 1) * \lfloor\frac{to_k - from_k}{M - 1}\rceil$ \Comment{Découpage en $M$ éléments équidistants}
        \State ajustement du modèle $\mathcal{M}$ avec $K[i]$ éléments mémoire
        \State $BIC[i] \gets calcul du BIC de \mathcal{M}$
    \EndFor
    \State $i_{opt} \gets argmin\ BIC$
    \State $K_{opt} \gets K[i_{opt}]$
    \State $from_k \gets K[i_{opt} - 1];\ to_k \gets K[i_{opt} + 1]$ \Comment{Mise à jour des bornes en encadrant le minimum}
\EndWhile
\end{algorithmic}

\qquad Le nombre de composants autorégressifs pouvant être grand, il faut les lier aux $\alpha_k$ avec un modèle de régression.
Pour cela, nous avons utilisé une régression bi-exponentielle double :
$$BiExp(lag) = A_1 e^{-e^{lrc_1} lag} + A_2 e^{-e^{lrc_2} lag}$$
Cela permet de réduire le nombre de coefficients de $K_{opt}$ à $4$, ce qui est doublement bénéfique : le temps d'ajustement des modèles est grandement réduit et lors de la construction des intervalles de confiance de nos coefficients, l'accumulation des variances est limitée.

\qquad Le modèle complet s'exprime donc ainsi :
$$log(\lambda_i(t)) = \beta_0 + b_i + spline(D_i(t)) \beta_D + \sum_{k=1}^{K_{opt}} \textcolor{blue}{(A_1 e^{-e^{lrc_1} k} + A_2 e^{-e^{lrc_2} k})} Y_i(t-k) + spline(E_i(t)) \beta_E$$

## Effet de médiation de la profondeur

\qquad Il est possible que l'exposition à des perturbations conduisent les narvals à :

1. émettre moins de buzz,
2. moins plonger ou plonger moins profondément.

Mais il existe également un lien entre la profondeur d'immersion des baleines et leur production de buzz.
Aussi, il se peut que l'exposition ait un lien direct sur l'émission de buzz et un lien indirect via son effet sur la profondeur.

\qquad Afin de représenter uniquement le lien direct, les coefficients des covariables autres que l'exposition sont estimés sans inclure celle-ci à partir des observations effectuées sans soumettre les animaux à des perturbations :
$$log(\lambda_i(t)) = \beta_0 + b_i + spline(D_i(t)) \beta_D + \sum_{k=1}^{K_{opt}} A_1 e^{-e^{lrc_1} k} + A_2 e^{-e^{lrc_2} k} Y_i(t-k)$$
Nous obtenons donc les estimations $\widehat{\beta_D},\ \widehat{A_1},\ \widehat{lrc_1},\ \widehat{A_2},\ \widehat{lrc_2}$ qui sont ensuite injectées dans le modèle complet au moyen d'un terme d'\say{offset} (non réestimé) z :
$$offset_i(t) = spline(D_i(t)) \widehat{\beta_D} + \sum_{k=1}^{K_{opt}} (\widehat{A_1} e^{-e^{\widehat{lrc_1}} k} + \widehat{A_2} e^{-e^{\widehat{lrc_2}} k}) Y_i(t-k)$$
Le modèle incluant l'exposition est donc reformulé ainsi :
$$log(\lambda_i(t)) = \beta_0 + b_i + \textcolor{blue}{offset_i(t)} + spline(E_i(t)) \beta_E$$
Et les paramètres estimés $\widehat{\beta_E}$ permettront d'interpréter l'effet de l'exposition par rapport à des conditions \say{normales}.

## Intervalles de confiance

### Construction par approche Monte Carlo

\qquad Après avoir estimé les coefficients associés à l'exposition aux perturbations, nous souhaitons construire les intervalles de confiance de ces estimations.
L'approche classique de calcul des intervalles de confiance se basant sur la seule variance estimée des coefficients d'exposition donnerait ici des résultats incorrects, la variance des coefficients de profondeur et d'autorégression ne serait alors pas prise en compte car tuée par l'utilisation de l'offset.
Nous avons donc utilisé l'approche Monte-Carlo suivante :

\begin{algorithmic}
\State $M \gets 1000$ \Comment{Nombre de répétitions de la procédure}
\State $\widehat{\beta_E} \gets []$
\For{$i \in \{1, ..., M\}$}
    \Comment{Tirage aléatoire des coefficients de profondeur et autorégressifs}
    \State $\widehat{\beta_D} \gets \mathcal{N}(\mathbb{E}(\beta_D), \mathbb{V}ar(\beta_D))$
    \State $\widehat{A_1} \gets \mathcal{N}(\mathbb{E}(A_1), \mathbb{V}ar(A_1))$
    \State $\widehat{lrc_1} \gets \mathcal{N}(\mathbb{E}(lrc_1), \mathbb{V}ar(lrc_1))$
    \State $\widehat{A_2} \gets \mathcal{N}(\mathbb{E}(A_2), \mathbb{V}ar(A_2))$
    \State $\widehat{lrc_2} \gets \mathcal{N}(\mathbb{E}(lrc_2), \mathbb{V}ar(lrc_2))$
    \State calcul de l'offset avec $\widehat{\beta_D},\ \widehat{A_1},\ \widehat{lrc_1},\ \widehat{A_2},\ \widehat{lrc_2}$
    \State ajustement du modèle $\mathcal{M}$ en fixant l'offset
    \State $\widehat{\beta_E}[i] \gets$ coefficients de profondeur ajustés de $\mathcal{M}$
\EndFor
\State $IC_\alpha \gets [q_{\alpha / 2}^{\widehat{\beta_E}}, q_{1 - \alpha / 2}^{\widehat{\beta_E}}]$ \Comment{Estimation via les quantiles empiriques}
\end{algorithmic}

### Estimation de bandes de prédiction via la méthode Delta {#delta}

\qquad Une fois les coefficients d'exposition $\widehat{\beta_E}$ estimés nous pouvons prédire le taux d'émission de buzz sur l'ensemble d'un intervalle de niveau d'exposition aux perturbations.
Afin d'associer une bande de confiance à la prédiction moyenne nous avons appliqué la méthode Delta pour calculer la variance du taux d'émission.

Tout d'abord, d'après le Théorème Central Limite on a : $\sqrt{n} (\widehat{\beta} - \beta) \sim \mathcal{N}(0, \Sigma)$ avec $\widehat{\beta}$ les coefficients estimés du modèle et $\Sigma$ leur variance.

Etant donné que nous utilisons un GLM avec un lien log, le taux d'émission est lié aux coefficients du modèle via la relation $\lambda(t) = exp(X(t) \beta) \vcentcolon = f(\beta)$.
Le gradient de la fonction $f$ vaut $\nabla f(\beta) = X f(\beta)$.

Ainsi, quand on applique la méthode Delta on obtient :
\begin{align*}
    \sqrt{n} (f(\widehat{\beta}) - f(\beta)) &\xrightarrow[]{\mathcal{L}} \mathcal{N}(0, \nabla f(\beta)^T \Sigma \nabla f(\beta)) \\
    \Leftrightarrow \sqrt{n} (\widehat{\lambda(t)}) - \lambda(t)) &\xrightarrow[]{\mathcal{L}} \mathcal{N}(0, \lambda(t)^2 X(t)^T \Sigma X(t))
\end{align*}
donc
$$
\frac{\sqrt{n}}{\widehat{\lambda(t)} \sqrt{X(t)^T \widehat{\Sigma} X(t)}} (\widehat{\lambda(t)}) - \lambda(t)) \rightsquigarrow \mathcal{N}(0, 1)
$$
On en déduit la bande de confiance au niveau $\alpha$ :
$$
IC_\alpha(\lambda(t)) = [\widehat{\lambda(t)} \pm q_{1 - \alpha / 2}^\mathcal{N} \frac{\widehat{\lambda(t)} \sqrt{X(t)^T \widehat{\Sigma} X(t)}}{\sqrt{n}}]
$$
où $q_{1 - \alpha / 2}^\mathcal{N}$ est le quantile $1 - \alpha / 2$ de la loi normale centrée réduite.

# Résultats

## Note sur le temps d'ajustement des modèles

```{r}
glm.profiling <- as.data.frame(readRDS("../../data/1_buzzing/glm_buzz_depth_maxlag_profiling/profiling.rds"))
glm.profiling$maxlag <- as.numeric(rownames(glm.profiling))

glmer.profiling <- as.data.frame(readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag_profiling/profiling.rds"))
glmer.profiling$maxlag <- as.numeric(rownames(glmer.profiling))
```

\qquad Le temps d'ajustement des modèles, et en particulier des modèles mixtes, augmente fortement lorsque que le nombre de paramètres à ajuster augmente. \newline
Comme nous pouvons le voir sur la Figure \@ref(fig:glm-time) cette augmentation est linéaire pour les modèles classiques, alors que pour les modèles mixtes celle-ci est quadratique.

```{r glm-time, fig.width = 8, fig.cap = "Courbes pleines : temps d'ajustement (en secondes) des modèles en fonction de la mémoire maximum ; courbes en pointillés : $f(x) = x$ à gauche et $f(x) = x^{2.5}$ à droite."}
g1 <- ggplot(glm.profiling, aes(x = maxlag, y = total_time, group = 1)) +
  geom_line() +
  geom_point() +
  geom_function(fun = function(x) { x }, linetype = "dashed") +
  labs(x = "Composants mémoire",
       y = "Temps d'ajustement [secondes]",
       caption = "Modèles classiques") +
  theme(plot.margin = margin(0, 0, 0, 0, "pt"))

g2 <- ggplot(glmer.profiling, aes(x = maxlag, y = total_time, group = 1)) +
  geom_line() +
  geom_point() +
  geom_function(fun = function(x) { x^2.5 }, linetype = "dashed") +
  labs(x = "Composants mémoire",
       y = "Temps d'ajustement [secondes]",
       caption = "Modèles mixtes") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 1, "pt"))

g1 + g2
```

## Recherche de la mémoire optimale

```{r}
maxlag.bic <- readRDS("../../data/1_buzzing/glm_buzz_depth_maxlag/maxlag.bic.rds")
maxlag.opt <- as.integer(maxlag.bic[which.min(maxlag.bic[, 2]), 1])
maxlag.glmer.bic <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/maxlag.bic.rds")
maxlag.glmer.opt <- as.integer(maxlag.glmer.bic[which.min(maxlag.glmer.bic[, 2]), 1])
```

\qquad Le temps d'ajustement des modèles mixtes étant nettement plus important que ceux des modèles sans effets aléatoires, nous avons dans un premier temps exclu ces effets du modèle sans exposition pour estimer la mémoire optimale.
Nous avons choisi pour la recherche $K_{min} = 1,\ K_{max} = 300,\ M = 10$.
Nous obtenons une mémoire optimale de `r maxlag.opt` secondes.
Cela nous a permis de restreindre tout de suite l'ensemble de recherche initial à $K_{min} = 1,\ K_{max} = 300$ quand nous avons considéré le modèle incluant les effets aléatoires.
De même que précédemment, la mémoire optimale est égale à `r maxlag.glmer.opt` secondes.
La Figure \@ref(fig:maxlag-bic) permet de voir que dans les deux cas les optimums semblent bien correspondre à des minimums globaux.

```{r maxlag-bic, fig.width = 8, fig.cap = "BIC en fonction de la mémoire maximum."}
g1 <- ggplot(maxlag.bic, aes(x = maxlag, y = BIC)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = maxlag.opt, col = "blue", lty = 2) +
  labs(x = "Mémoire maximum [secondes]", caption = "Modèles classiques")
g2 <- ggplot(maxlag.glmer.bic, aes(x = maxlag, y = BIC)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = maxlag.glmer.opt, col = "blue", lty = 2) +
  labs(x = "Mémoire maximum [secondes]", caption = "Modèles mixtes")

g1 + g2
```

## Régression double bi-exponentielle sur les coefficients autorégressifs

\qquad La Figure \@ref(fig:biexp-AR) permet de comparer la régression double bi-exponentielle et les composantes de la mémoire ajustées pour un décalage maximum de `r maxlag.opt`.
Nous pouvons constater que l'ajustement par la double bi-exponentielle est très fidèle aux `r maxlag.opt` coefficients initiaux.

```{r}
ARcoefs.fit <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/ARcoef.fit.rds")
```

```{r biexp-AR, fig.cap = "Régression bi-exponentielle des coefficients autorégressifs."}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

Les 4 coefficients obtenus suite à la régression double bi-exponentielle sont présentés dans la Table \@ref(tab:coef-biexp-AR).
Nous pouvons noter que leurs erreurs standard sont faibles, ce qui est cohérent avec la validation visuelle de la régression.

```{r}
RegBiExp.coefs <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/ARcoef.RegBiExp.rds")
```

```{r coef-biexp-AR}
df <- data.frame(RegBiExp.coefs[, c("estimate", "std.error")])
row.names(df) <- c("$A_1$", "$lrc_1$", "$A_2$", "$lrc_2$")
kable(df,
      col.names = c("moyenne", "erreur standard"),
      caption = "Coefficients autorégressifs obtenus par régression bi-exponentielle",
      label = "coef-biexp-AR",
      digits = 3,
      escape = FALSE) %>%
  kable_styling(latex_options = "HOLD_position")
```

## Impact de l'exposition aux perturbations sur le taux d'émission de buzz

\qquad La Table \@ref(tab:coef-glmer-expo) expose les coefficients associés à l'exposition du modèle mixte.
Interpréter les valeurs des coefficients liés à des splines étant peu pertinent, nous préférons nous référer à la lecture de la Figure \@ref(fig:mod-expo-rate) sur laquelle nous représentons les estimations du modèle pour le taux d'émission de buzz selon la distance avec le bateau.
Il apparaît alors clairement que plus le bateau est loin, plus le taux d'émission de buzz est élevé.

```{r}
predFrame <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_pred/predFrame.rds")
predFramePop <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_pred/predFramePop.rds")
```

```{r mod-expo-rate, fig.cap = "Evolution du taux d'émission de buzz selon la distance au bateau."}
ggplot(data = predFrame, aes(x = 1 / X, y = 60 * exp(predBuzz), color = Ind)) +
  geom_line() +
  geom_line(data = predFramePop, aes(x = 1 / X, y = 60 * exp(predBuzzPop)), size = 1.2, color = "black") +
  xlim(0, 50) +
  xlab("Distance avec le bateau [km]") +
  ylab("Taux d'émission de buzz [1/min]") +
  scale_color_discrete(name = "Baleine")
```

```{r}
glmerAllBuzzDepth.tidy <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/glmerAllBuzzDepth.tidy.rds")
glmerAllBuzzDepth.glance <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/glmerAllBuzzDepth.glance.rds")
acf.plot.data <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/acf.plot.data.rds")
QQ.plot.data <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/QQ.plot.data.rds")
z.plot.data <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo/z.plot.data.rds")
```

```{r coef-glmer-expo}
df <- data.frame(glmerAllBuzzDepth.tidy[2:4, c("estimate", "std.error")])
row.names(df) <- c("$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("moyenne", "erreur standard"),
      caption = "Coefficients d'exposition.",
      label = "coef-glmer-expo",
      digits = 3,
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position"))
```

La Figure \@ref(fig:mod-expo-val) présente plusieurs graphiques utiles pour valider visuellement le modèle : nous sommes satisfaits de l'absence de corrélation entre les résidus constatée sur les deux premiers et du comportement gaussien visible sur le dernier.

```{r mod-expo-val, fig.height = 5, fig.cap = "Validation graphique du modèle."}
g1 <- ggplot(data = acf.plot.data, aes(x = lag, y = acf)) +
  geom_col(size = .2) +
  labs(x = "Décalage", y = "Autocorrélation",
       caption = "Autocorrélation des résidus") +
  theme(plot.margin = margin(0, 0, 1, 0, "pt"))

g2 <- ggplot(data = z.plot.data[2:nrow(z.plot.data),], aes(x = Zlow, y = Zupp)) +
  geom_point(size = .25) +
  labs(x = TeX("$Z_{i+1}$"), y = TeX("$Z_{i}$"),
       caption = "Résidu selon le précédent") +
  coord_fixed() +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g3 <- ggplot(QQ.plot.data, aes(x = qunif, y = qZ)) +
  geom_point(size = .5) +
  geom_abline(slope = 1, intercept = 0, size = 1, linetype = "dashed") +
  labs(x = "Quantiles uniformes théoriques ", y = "Quantiles empiriques",
       caption = "Q-Q plot") +
  coord_fixed() +
  theme(plot.margin = margin(0, 0, 0, 0, "pt"))

g1 / (g2 + g3)
```

## Intervalles de confiance

### Coefficients d'exposition

#### Utilisation de lois normales univariées

Dans un premier temps, nous avons considéré que les coefficients autorégressifs et de profondeur suivaient chacun une loi normale centrée sur leur estimation moyenne et avec une variance égale au carré de leur erreur standard.
Nous avons donc 4 lois normales univariées pour les coefficients de la régression double bi-exponentielle et 4 autres pour la spline sur la profondeur.

```{r}
glmer.coefs <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/ARcoef.best.rds")
```

```{r}
B <- 1000
A1 <- rnorm(B, RegBiExp.coefs$estimate[1], RegBiExp.coefs$std.error[1])
lrc1 <- rnorm(B, RegBiExp.coefs$estimate[2], RegBiExp.coefs$std.error[2])
A2 <- rnorm(B, RegBiExp.coefs$estimate[3], RegBiExp.coefs$std.error[3])
lrc2 <- rnorm(B, RegBiExp.coefs$estimate[4], RegBiExp.coefs$std.error[4])
ARcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- BiExp(A1[[b]], lrc1[[b]], A2[[b]], lrc2[[b]], lag = ARcoefs.fit$lag)
  data.frame(lag = ARcoefs.fit$lag, estimate = estimate, b = as.factor(b))
}))

estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
  glmer.coefs$estimate[2:5]
Depthcoefs.fit <- data.frame(depth = -1000:0, estimate = estimate)
d1 <- rnorm(B, glmer.coefs$estimate[2], glmer.coefs$std.error[2])
d2 <- rnorm(B, glmer.coefs$estimate[3], glmer.coefs$std.error[3])
d3 <- rnorm(B, glmer.coefs$estimate[4], glmer.coefs$std.error[4])
d4 <- rnorm(B, glmer.coefs$estimate[5], glmer.coefs$std.error[5])
Depthcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
    c(d1[[b]], d2[[b]], d3[[b]], d4[[b]])
  data.frame(depth = -1000:0, estimate = estimate, b = as.factor(b))
}))
```

Sur la Figure \@ref(fig:coef-ar-norm) nous avons représenté les courbes des fonctions double bi-exponentielles ainsi générées.
Nous pouvons voir que leurs allures semblent toujours suivre celle de la régression initiale.

```{r coef-ar-norm, fig.cap = "Variation des coefficients autorégressif selon des lois normales univariées."}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_line(data = ARcoefs.fit.mc, aes(x = lag, y = estimate, group = b), alpha = .1, col = "red") +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

Nous avons fait de même avec les coefficients de profondeur, et nous pouvons remarquer sur la Figure \@ref(fig:coef-depth-norm) que cette fois-ci certaines courbes s'éloignent sensiblement de l'interpolation moyenne.

```{r coef-depth-norm, fig.cap = "Variation des coefficients de profondeur selon des lois normales univariées."}
ggplot(Depthcoefs.fit) +
  geom_line(data = Depthcoefs.fit.mc, aes(x = depth, y = estimate, group = b), alpha = .1, col = "red") +
  geom_line(aes(x = depth, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Profondeur [mètres]", y = "ns")
```

```{r}
expo.coef <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_par/expo.coef.norm.rds")

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

alpha <- .05
expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

Les intervalles de confiance calculés avec la procédure Monte Carlo sont donnés sur la Table \@ref(tab:coef-expo-ci-norm).
Nous avons également affiché les valeurs médianes des intervalles de confiance calculés à chaque répétition sur la base de la variation des coefficients d'exposition uniquement.
Il est flagrant que les intervalles Monte Carlo sont bien plus larges et ne permettent en aucun cas de conclure sur un effet de l'exposition sur le taux d'émission de buzz.

```{r coef-expo-ci-norm}
df <- data.frame(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint))
row.names(df) <- c("$\\beta_0$", "$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("inf", "sup", "inf", "sup"),
      caption = "Intervalles de confiance dans le cas de normales univariées.",
      label = "coef-expo-ci-norm",
      digits = 3,
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position")) %>%
  add_header_above(c(" " = 1, "Monte Carlo" = 2, "Erreur standard" = 2))
```

La Figure \@ref(fig:coef-expo-ci-norm-dist) donne une représentation graphique de ces intervalles (en rouge les "MC" et en bleu les "SE"), ainsi que des distributions des coefficients.

```{r coef-expo-ci-norm-dist, fig.height = 5, fig.cap = "Intervalles de confiance dans le cas de normales univariées."}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_1}$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_2}$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_3}$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

#### Utilisation d'une loi normale multivariée {#mvnorm}

L'une des explications aux très larges intervalles de confiance observés dans la section précédente pourrait être que nous avons accumulé les variances des coefficients sans tenir compte des probables covariances existant entre les coefficients.
Afin de corriger cela nous avons répété l'approche décrite précédemment, mais en tirant les coefficients dans des lois normales multivariées (une pour les coefficients de la régression double bi-exponentielle et une pour les coefficients de la spline) toujours centrées sur les estimations moyennes, mais ayant des matrices de variance-covariance non diagonales.
Dorénavant nous avons donc une loi normale multivariée pour les coefficients de la régression double bi-exponentielle et une autre pour la profondeur, les deux étant de dimension 4.

```{r}
RegBiExp.vcov <- readRDS("../../data/1_buzzing/glmer_buzz_depth_maxlag/RegBiExp.vcov.rds")
ARcoefs <- rmvnorm(B, mean = RegBiExp.coefs$estimate, sigma = RegBiExp.vcov,
                   checkSymmetry = FALSE)
ARcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- BiExp(ARcoefs[b, 1], ARcoefs[b, 2], ARcoefs[b, 3], ARcoefs[b, 4],
                    lag = ARcoefs.fit$lag)
  data.frame(lag = ARcoefs.fit$lag, estimate = estimate, b = as.factor(b))
}))

estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
  glmer.coefs$estimate[2:5]
Depthcoefs.fit <- data.frame(depth = -1000:0, estimate = estimate)
Depth.vcov <- as.matrix(readRDS("../../data/1_buzzing/glmer_buzz_ARDepth/glmERBuzzARDepth.vcov.rds"))[2:5, 2:5]
Depthcoefs <- rmvnorm(B, mean = glmer.coefs$estimate[2:5], sigma = Depth.vcov,
                      checkSymmetry = FALSE)
Depthcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
    c(Depthcoefs[b, 1], Depthcoefs[b, 2], Depthcoefs[b, 3], Depthcoefs[b, 4])
  data.frame(depth = -1000:0, estimate = estimate, b = as.factor(b))
}))
```

La Figure \@ref(fig:coef-ar-mvnorm) montre que la régression biexponentielle initiale est encore plus fidèlement suivie qu'auparavant.

```{r coef-ar-mvnorm, fig.cap = "Variation des coefficients autorégressifs selon une loi normale multivariée."}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_line(data = ARcoefs.fit.mc, aes(x = lag, y = estimate, group = b), alpha = .1, col = "red") +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

Et surtout, comme nous pouvons le voir sur la Figure \@ref(fig:coef-depth-mvnorm), il en va de même pour la profondeur, alors que précédemment les tirages donnaient des courbes fortement éloignées de celle attendue.

```{r coef-depth-mvnorm, fig.cap = "Variation des coefficients de profondeur selon une loi normale multivariée."}
ggplot(Depthcoefs.fit) +
  geom_line(data = Depthcoefs.fit.mc, aes(x = depth, y = estimate, group = b), alpha = .1, col = "red") +
  geom_line(aes(x = depth, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Profondeur [mètres]", y = "ns")
```

```{r}
expo.coef <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_par/expo.coef.mvnorm.biexp.rds")

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

Sur la Table \@ref(tab:coef-expo-ci-mvnorm) nous pouvons constater que les intervalles de confiance estimés en utilisant des lois normales multivariées sont nettement plus petits et peuvent conduire à conclure sur un effet de l'exposition sur le taux d'émission de buzz.

```{r coef-expo-ci-mvnorm}
df <- data.frame(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint))
row.names(df) <- c("$\\beta_0$", "$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("inf", "sup", "inf", "sup"),
      caption = "Intervalles de confiance dans le cas de normales multivariées.",
      label = "coef-expo-ci-mvnorm",
      digits = 3,
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position")) %>%
  add_header_above(c(" " = 1, "Monte Carlo" = 2, "Erreur standard" = 2))
```

Nous pouvons également voir sur la Figure \@ref(fig:coef-expo-ci-mvnorm-dist) que les distributions semblent normales, contrairement à celles observées avec les lois univariées.

```{r coef-expo-ci-mvnorm-dist, fig.height = 5, fig.cap = "Intervalles de confiance dans le cas de normales multivariées."}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_1}$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_2}$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_3}$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

#### Variance-covariance des coefficients autorégressifs

Bien que plus intéressante, la procédure que nous avons mise en place se base sur la matrice de variance-covariance des coefficients de la régression double bi-exponentielle, ce qui signifie que nous ne captons pas directement la variabilité du phénomène autorégressif mais plutôt celle de la régression double bi-exponentielle.
Pour palier cette approximation nous avons tenté d'estimer la matrice de variance-covariance des coefficients autorégressifs, à nouveau par une procédure Monte Carlo.
Cette fois-ci nous répétons 1000 fois le tirage des 60 coefficients de mémoire à partir d'une loi normale multivariée et à chaque fois nous ajustons une régression double bi-exponentielle sur les 60 coefficients tirés ; finalement nous pouvons obtenir les estimations moyennes des coefficients de la double bi-exponentielle, ainsi que la matrice de variance-covariance associée.
Nous reprenons enfin la procédure Monte Carlo employée dans la section précédente avec le vecteur de moyennes et la matrice de variance-covariance obtenus.

```{r}
biexp.coef.cov <- readRDS("../../data/1_buzzing/glmer_biexp_AR_mc/biexp.coef.cov.rds")
biexp.coef.estimate <- readRDS("../../data/1_buzzing/glmer_biexp_AR_mc/biexp.coef.estimate.rds")
ARcoefs <- rmvnorm(B, mean = apply(biexp.coef.estimate, 2, mean),
                   sigma = biexp.coef.cov,
                   checkSymmetry = FALSE)
ARcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- BiExp(ARcoefs[b, 1], ARcoefs[b, 3], ARcoefs[b, 2], ARcoefs[b, 4],
                    lag = ARcoefs.fit$lag)
  data.frame(lag = ARcoefs.fit$lag, estimate = estimate, b = as.factor(b))
}))
```

Nous pouvons contrôler sur la Figure \@ref(fig:coef-ar-mvnorm-mc) que les régressions double bi-exponentielles obtenues restent cohérentes.

```{r coef-ar-mvnorm-mc, fig.cap = "Variation des coefficients autorégressif selon une loi normale multivariée estimée par Monte Carlo."}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_line(data = ARcoefs.fit.mc, aes(x = lag, y = estimate, group = b), alpha = .1, col = "red") +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

```{r}
expo.coef <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_par/expo.coef.mvnorm.mc.rds")

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

La Table \@ref(tab:coef-expo-ci-mvnorm-mc) et la Figure \@ref(fig:coef-expo-ci-mvnorm-dist-mc) permettent de vérifier que bien que les intervalles calculés ainsi sont légèrement plus grands que les précédents, ils permettent toujours d'interpréter les coefficients d'exposition ajustés par le modèle.

```{r coef-expo-ci-mvnorm-mc}
df <- data.frame(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint))
row.names(df) <- c("$\\beta_0$", "$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("inf", "sup", "inf", "sup"),
      caption = "Intervalles de confiance dans le cas d'une normale multivariée estimée par Monte Carlo.",
      label = "coef-expo-ci-mvnorm-mc",
      digits = 3,
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position")) %>%
  add_header_above(c(" " = 1, "Monte Carlo" = 2, "Erreur standard" = 2))
```

```{r coef-expo-ci-mvnorm-dist-mc, fig.height = 5, fig.cap = "Intervalles de confiance dans le cas d'une normale multivariée estimée par Monte Carlo."}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_1}$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_2}$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_3}$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

#### Sans passer par la régression biexponentielle

L'intérêt de la régression biexponentielle était de :

1. réduire le temps d'ajustement des modèles linéaires,
2. éviter d'accumuler les variances des 60 coefficients de mémoire.

En fixant les coefficients autorégressifs, avoir 4 ou 60 coefficients pour la mémoire n'importe plus ; et en utilisant une loi normale multivariée, nous devrions également ne plus accumuler directement les variances des coefficients.
Ainsi, nous avons tenté de nous passer de la régression double bi-exponentielle, et donc de tirer les 60 coefficients mémoire et les 4 coefficients de profondeur directement dans une seule loi normale multivariée.

```{r}
expo.coef <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_par/expo.coef.mvnorm.rds")

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

Nous pouvons voir sur la Table \@ref(tab:coef-expo-ci-mvnorm-full) et la Figure \@ref(fig:coef-expo-ci-mvnorm-dist-full) qu'avec cette approche plus directe, les intervalles de confiance sont quasiment identiques à ceux obtenus dans la section \@ref(mvnorm), et même plus petit pour l'ordonnée à l'origine.

```{r coef-expo-ci-mvnorm-full}
df <- data.frame(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint))
row.names(df) <- c("$\\beta_0$", "$\\beta_{E_1}$", "$\\beta_{E_2}$", "$\\beta_{E_3}$")
kable(df,
      col.names = c("inf", "sup", "inf", "sup"),
      caption = "Intervalles de confiance dans le cas d'une loi normale multivariée sans double bi-exponentielle.",
      label = "coef-expo-ci-mvnorm-full",
      digits = 3,
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position")) %>%
  add_header_above(c(" " = 1, "Monte Carlo" = 2, "Erreur standard" = 2))
```

```{r coef-expo-ci-mvnorm-dist-full, fig.height = 5, fig.cap = "Intervalles de confiance dans le cas d'une loi normale multivariée sans double bi-exponentielle."}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_1}$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_2}$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_{E_3}$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

### Pourcentage du taux normal d'émission de buzz

\qquad Il est rassurant de voir que les intervalles de confiance des coefficients d'exposition obtenus par Monte Carlo restent raisonnablement petits, cependant comme évoqué précédemment, il n'est pas possible de lier une augmentation ou une diminution du taux d'émission de buzz en fonction de la distance avec le bateau à partir de leur valeur.
C'est pourquoi nous avions représenté graphiquement cette évolution sur la Figure \@ref(fig:mod-expo-rate), mais cette visualisation ne proposait pas d'intervalle de confiance ou de bande de prédiction.

Nous avons employé la méthode Delta décrite dans la section \@ref(delta) pour construire une bande de confiance autour de l'estimation du pourcentage du taux normal d'émission de buzz en fonction de la profondeur.
Ce pourcentage est obtenu en faisant le rapport entre l'intensité estimée avec et sans perturbation.
La Figure \@ref(fig:mod-expo-rate-per) permet de voir que la bande de confiance tracée en rouge est fine. Nous sommes donc confiants dans la lecture de la courbe qui illustre que soumissent à des perturbations à une distance inférieure à 15 kilomètres, les narvals commencent à émettre nettement moins de buzz que dans des conditions normales.
Afin de comparer l'approche de la méthode Delta, nous avons utilisé la fonction *predictInterval* du package **merTools**.
Celle-ci permet d'obtenir une bande de prédiction pour des modèles mixtes par une approche Monte Carlo.
Comme nous pouvons le voir sur la Figure \@ref(fig:mod-expo-rate-per), la bande obtenue ainsi (tracée en bleue) suit la même forme que celle de la méthode Delta.

```{r}
ChangePop <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_pred/ChangePop.rds")
ChangePop_merTools <- readRDS("../../data/1_buzzing/glmer_buzz_ARDepth_expo_pred_merTools/ChangePop.rds")
```

```{r mod-expo-rate-per, fig.cap = "Pourcentage du taux normal d'émission de buzz selon la distance au bateau."}
ggplot(data = ChangePop, aes(x = 1 / X, y = change)) +
  geom_line(size = .5) +
  geom_ribbon(aes(ymin = change - CI, ymax = change + CI, fill = "delta"),
              alpha = .25, linetype = 0) +
  geom_ribbon(data = ChangePop_merTools, aes(y = fit, ymin = lwr, ymax = upr,
                                             fill = "merTools"),
              alpha = .25, linetype = 0) +
  scale_fill_manual(name = "Méthode", values = c("delta" = "red", "merTools" = "blue")) +
  xlim(0, 50) +
  xlab("Distance avec le bateau [km]") +
  ylab("Pourcentage du taux normal d'émission")
```
