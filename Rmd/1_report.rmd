---
title: "Buzzing - Rapport d'avancement"
output:
  bookdown::pdf_document2:
    toc: true
    toc_depth: 3
toc-title: "Sommaire"
urlcolor: blue
linkcolor: blue
header-includes:
    \usepackage{float}
    \makeatletter\renewcommand*{\fps@figure}{H}\makeatother
---

```{r setup, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE,
                      comment = NA, warning = FALSE,
                      message = FALSE)
knitr::opts_chunk$set(fig.width = 8, fig.height = 4, fig.align = "center")
```

```{r}
library(ggplot2)
library(kableExtra)
library(latex2exp)
library(mvtnorm)
library(patchwork)
library(reshape2)
library(splines)

source("../R/utils/1_biexp.R")
source("../R/utils/1_monte_carlo_conf_int.R")

set.seed(15)
```

\newpage

Nous souhaitons observer chez des narvals l'effet de l'exposition à des perturbations humaines sur leur capacité à se nourrir. Lorsqu'elles se nourissent, ces baleines émettent des sons spécifiques (buzz). Nous nous intéresserons donc à la fréquence d'émission de ces buzz (buzz/min), ce qui peut être modélisé par un modèle de Poisson.

# Modélisation du buzzing chez les narvals sans exposition

## Estimation de l'effet de la profondeur

Pour se nourrir, les narvals doivent plonger profondément alors que le reste du temps, ils restent "proche" de la surface. Il faut donc inclure au modèle la profondeur à laquelle se trouvent les baleines quand elles émettent ou non des buzz. La relation entre l'émission de buzz et la profondeur n'étant pas linéaire, la profondeur a été remplacée par une variable explicative la décrivant par un polynôme de degré 3.

## Estimation de l'autocorrélation dans l'émission de buzz

### Recherche de la mémoire optimale

L'émission d'un buzz à un instant $t$ est corrélé à l'émission ou non de buzz aux instants précédents $t$. Cet effet mémoire doit donc être ajouté au modèle et pour cela nous devons déterminer la mémoire maximum qu'il faut autoriser au modèle.

Afin de trouver la mémoire optimale, nous avons utilisé la démarche suivante :

1. $from.ml = 1\ ;\ to.ml = N$
2. Tant que $(to.ml - from.ml > 2)$ :
   1. Pour $ml^k_i = from.ml + (i-1) * \lfloor\frac{to.ml-from.ml}{M-1}\rceil,\ i = 1...M$ :
      1. ajustement d'un modèle de Poisson avec $ml^k_i$ éléments mémoire
      2. calcul du BIC
   2. $i_{opt} = argmin\ BIC_i$
   3. $ml_{opt} = ml^{k}_{i_{opt}}$
   4. $from.ml = ml^{k}_{i_{opt}-1}\ ;\ to.ml = ml^{k}_{i_{opt}+1}$

#### Sans effets aléatoires

Dans un premier temps, nous n'avons pas inclus d'effets aléatoires sur les individus pour estimer la mémoire optimale :
$$
Buzz \sim Ind + spline(Depth) + Lag_1 + ... + Lag_N
$$
Nous avons fixé $N = 300$ et $M = 10$.

```{r}
maxlag.bic <- readRDS("../data/glm_buzz_depth_maxlag/maxlag.bic.rds")
maxlag.opt <- as.integer(maxlag.bic[which.min(maxlag.bic[, 2]), 1])
```

Nous obtenons une mémoire optimale de `r maxlag.opt` secondes. La figure \@ref(fig:plot-glm-bic) permet de voir que cet optimal semble bien correspondre à un minimum global.

```{r plot-glm-bic, fig.cap = "BIC en fonction de la mémoire maximum"}
ggplot(maxlag.bic, aes(x = maxlag, y = BIC)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = maxlag.opt, col = "blue", lty = 2) +
  labs(x = "Mémoire maximum [secondes]")
```

#### Avec effets aléatoires

Nous avons plusieurs observations par individu, ce qui implique qu'elles ne sont pas indépendantes. Pour prendre en compte cette dépendance, nous avons tenté d'inclure un effet aléatoire sur les individus :
$$
Buzz \sim (1 | Ind) + spline(Depth) + Lag_1 + ... + Lag_N
$$
Compte tenu du résultat obtenu précédemment, nous avons tout de suite restreint l'intervalle de recherche initial à $[30, 90]$.

```{r}
maxlag.glmer.bic <- readRDS("../data/glmER_buzz_depth_maxlag/maxlag.bic.rds")
maxlag.glmer.opt <- as.integer(maxlag.glmer.bic[which.min(maxlag.glmer.bic[, 2]), 1])
```

La figure \@ref(fig:plot-glmer-bic) présente les résultats obtenus. La courbe est similaire à celle obtenue sans l'ajout d'effets aléatoires.

```{r plot-glmer-bic, fig.cap = "BIC en fonction de la mémoire maximum - modèle mixte"}
ggplot(maxlag.glmer.bic, aes(x = maxlag, y = BIC)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = maxlag.glmer.opt, col = "blue", lty = 2) +
  labs(x = "Mémoire maximum [secondes]")
```

### Note sur le temps d'ajustement des modèles

Le temps d'ajustement des modèles, et en particulier des modèles mixtes, augmente fortement lorsque que le nombre de paramètres à ajuster augmentent. \newline
Comme nous pouvons le voir sur la figure \@ref(fig:plot-glm-time) cette augmentation est linéaire pour les modèles classiques, alors que pour les modèles mixtes celle-ci est quadratique.

```{r}
glm.profiling <- as.data.frame(readRDS("../data/glm_buzz_depth_maxlag_profiling/profiling.rds"))
glm.profiling$maxlag <- as.numeric(rownames(glm.profiling))

glmer.profiling <- as.data.frame(readRDS("../data/glmer_buzz_depth_maxlag_profiling/profiling.rds"))
glmer.profiling$maxlag <- as.numeric(rownames(glmer.profiling))
```

```{r plot-glm-time, fig.cap = "Temps d'ajustement (en secondes) des modèles en fonction de la mémoire maximum"}
g1 <- ggplot(glm.profiling, aes(x = maxlag, y = total_time, group = 1)) +
  geom_line() +
  geom_point() +
  geom_function(fun = function(x) { x }, linetype = "dashed") +
  labs(x = "Composants mémoire",
       y = "Temps d'ajustement [secondes]",
       caption = "Modèles classiques") +
  theme(plot.margin = margin(0, 0, 0, 0, "pt"))

g2 <- ggplot(glmer.profiling, aes(x = maxlag, y = total_time, group = 1)) +
  geom_line() +
  geom_point() +
  geom_function(fun = function(x) { x^2.5 }, linetype = "dashed") +
  labs(x = "Composants mémoire",
       y = "Temps d'ajustement [secondes]",
       caption = "Modèles mixtes") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 1, "pt"))

g1 + g2
```

### Régression bi-exponentielle sur les coefficients autorégressifs

Nous avons vu que les modèles mixtes sont bien plus longs à ajuster que les modèles classiques, aussi, afin de réduire le nombre de variables et le temps d'ajustement, nous appliquons une régression bi-exponentielle aux coefficients auto-régressifs obtenus précédemment. Ainsi nous passons de `r maxlag.opt` à 4 variables. \newline
La figure \@ref(fig:plot-AR-BiExp) illustre les composantes de la mémoire ajustées pour un décalage maximum de `r maxlag.opt`. Les points sont les contributions individuelles de chaque décalage, la courbe correspond à la régression bi-exponentielle.

```{r}
ARcoefs.fit <- readRDS("../data/glmER_buzz_depth_maxlag/ARcoef.fit.rds")
```

```{r plot-AR-BiExp, fig.cap = "Régression bi-exponentielle des coefficients auto-régressifs"}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

Les coefficients obtenus suite à la régression bi-exponentielle sont présentés dans la table \@ref(tab:tab-AR-BiExp).

```{r}
RegBiExp.coefs <- readRDS("../data/glmER_buzz_depth_maxlag/ARcoef.RegBiExp.rds")
```

```{r tab-AR-BiExp}
kable(RegBiExp.coefs, caption = "Coefficients autorégressifs obtenus par régression bi-exponentielle",
      label = "tab-AR-BiExp") %>%
  kable_styling(latex_options = "HOLD_position")
```

### Coefficients de profondeur

Les coefficients de profondeur du modèle linéaire mixte sans exposition sont proposés table \@ref(tab:tab-depth).

```{r}
glmer.coefs <- readRDS("../data/glmER_buzz_depth_maxlag/ARcoef.best.rds")
```

```{r tab-depth}
kable(glmer.coefs[2:5, c("term", "estimate", "std.error", "statistic", "p.value")],
      caption = "Coefficients de profondeur",
      label = "tab-depth") %>%
  kable_styling(latex_options = "HOLD_position")
```

# Estimation de l'effet de l'exposition sur le buzzing

## Modélisation

L'exposition aux perturbations est exprimée par $1/dist$ où $dist$ est la distance en kilomètres séparant l'animal du bateau dont émane la perturbation.

Nous avons ajusté le modèle mixte suivant :
$$
Buzz \sim (1 | Ind) + offset(ARDepth) + spline(Expo)
$$

Les coefficients estimés par le modèle mixte sans exposition sont fixés dans celui-ci afin que les coefficients ajustés pour la variable d'exposition s'interprètent comme un effet par rapport au comportement normal (sans exposition). De plus, cela permet de réduire sensiblement le coût calculatoire d'ajustement.

```{r}
glmerAllBuzzDepth.tidy <- readRDS("../data/glmer_buzz_ARDepth_expo/glmerAllBuzzDepth.tidy.rds")
glmerAllBuzzDepth.glance <- readRDS("../data/glmer_buzz_ARDepth_expo/glmerAllBuzzDepth.glance.rds")
acf.plot.data <- readRDS("../data/glmer_buzz_ARDepth_expo/acf.plot.data.rds")
QQ.plot.data <- readRDS("../data/glmer_buzz_ARDepth_expo/QQ.plot.data.rds")
z.plot.data <- readRDS("../data/glmer_buzz_ARDepth_expo/z.plot.data.rds")
```

```{r tab-coef-glmer-expo}
kable(glmerAllBuzzDepth.tidy, "latex",
      caption = "Coefficients du modèle mixte incluant l'exposition",
      label = "tab-coef-glmer-expo") %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"))
```

```{r tab-stat-glmer-expo}
kable(glmerAllBuzzDepth.glance, caption = "Statistiques du modèle mixte incluant l'exposition",
      label = "tab-stat-glmer-expo") %>%
  kable_styling(latex_options = "HOLD_position")
```

La figure \@ref(fig:mod-expo-val) présente plusieurs graphiques utiles pour valider visuellement le modèle : nous sommes satisfaits de l'absence de corrélation entre les résidus constatée sur les deux premiers et du comportement gaussien visible sur le dernier.

```{r mod-expo-val, fig.height = 8, fig.cap = "Validation graphique du modèle"}
g1 <- ggplot(data = acf.plot.data, aes(x = lag, y = acf)) +
  geom_col(size = .2) +
  labs(x = "Lag", y = "Autocorrelation of uniform residuals",
       caption = "Auto-corrélation des résidues") +
  theme(plot.margin = margin(0, 0, 1, 0, "pt"))

g2 <- ggplot(data = z.plot.data[2:nrow(z.plot.data),], aes(x = Zlow, y = Zupp)) +
  geom_point(size = .5) +
  labs(x = TeX("Z_{i+1}"), y = TeX("Z_{i}"),
       caption = "Résidue selon le précédent") +
  coord_fixed() +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g3 <- ggplot(QQ.plot.data, aes(x = qunif, y = qZ)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, size = 1, linetype = "dashed") +
  labs(x = "Uniform theoretical quantiles", y = "Empirical quantiles",
       caption = "Q-Q plot") +
  coord_fixed() +
  theme(plot.margin = margin(0, 0, 0, 0, "pt"))

g1 / (g2 + g3)
```

## Intervalles de confiance des coefficients d'exposition

Etant donné que nous avons fixé les coefficients associés à la profondeur et à l'effet mémoire aux valeurs obtenues sans exposition, l'estimation des intervalles de confiance des coefficients d'exposition ne peuvent être construits directement à partir de leurs erreurs standards, car la variabilité des coefficients de profondeur et d'effet mémoire ne serait pas prise en compte. Nous avons donc mis en place une approche Monte Carlo ajustant 1000 fois le modèle avec exposition tout en faisant varier les coefficients fixés, et permettant finalement d'estimer les intervalles de confiance des coefficients d'exposition via les quantiles des distributions obtenues.

### Variation des coefficients selon des lois normales univariées

Dans un premier temps, nous avons considéré que les coefficients suivaient chacun une loi normale centrée sur leur estimation moyenne et avec une variance égale au carré de leur erreur standard. Nous avons donc 4 lois normales univariées pour les coefficients de la régression biexponentille et 4 autres pour l'interpolation polynomiale par morceaux sur la profondeur.

```{r}
B <- 1000
A1 <- rnorm(B, RegBiExp.coefs$estimate[1], RegBiExp.coefs$std.error[1])
lrc1 <- rnorm(B, RegBiExp.coefs$estimate[2], RegBiExp.coefs$std.error[2])
A2 <- rnorm(B, RegBiExp.coefs$estimate[3], RegBiExp.coefs$std.error[3])
lrc2 <- rnorm(B, RegBiExp.coefs$estimate[4], RegBiExp.coefs$std.error[4])
ARcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- BiExp(A1[[b]], lrc1[[b]], A2[[b]], lrc2[[b]], lag = ARcoefs.fit$lag)
  data.frame(lag = ARcoefs.fit$lag, estimate = estimate, b = as.factor(b))
}))

estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
  glmer.coefs$estimate[2:5]
Depthcoefs.fit <- data.frame(depth = -1000:0, estimate = estimate)
d1 <- rnorm(B, glmer.coefs$estimate[2], glmer.coefs$std.error[2])
d2 <- rnorm(B, glmer.coefs$estimate[3], glmer.coefs$std.error[3])
d3 <- rnorm(B, glmer.coefs$estimate[4], glmer.coefs$std.error[4])
d4 <- rnorm(B, glmer.coefs$estimate[5], glmer.coefs$std.error[5])
Depthcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
    c(d1[[b]], d2[[b]], d3[[b]], d4[[b]])
  data.frame(depth = -1000:0, estimate = estimate, b = as.factor(b))
}))
```

Sur la figure \@ref(fig:coef-ar-norm) nous avons représenté les courbes des fonctions biexponentielles ainsi générées. Nous pouvons voir que leurs allures semblent toujours suivre celle de la régression initiale.

```{r coef-ar-norm, fig.cap = "Variation des coefficients autorégressif selon des lois normales univariées"}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_line(data = ARcoefs.fit.mc, aes(x = lag, y = estimate, group = b), alpha = .1, col = "red") +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

Nous avons fait de même avec les coefficients de profondeur, et nous pouvons remarquer sur la figure \@ref(fig:coef-depth-norm) que cette fois-ci l'allure de certaines courbes s'éloignent sensiblement de l'interpolation polynomiale moyenne.

```{r coef-depth-norm, fig.cap = "Variation des coefficients de profondeur selon des lois normales univariées"}
ggplot(Depthcoefs.fit) +
  geom_line(data = Depthcoefs.fit.mc, aes(x = depth, y = estimate, group = b), alpha = .1, col = "red") +
  geom_line(aes(x = depth, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Profondeur [mètres]", y = "ns")
```

```{r}
expo.coef <- readRDS("../data/glmer_buzz_ARDepth_expo_par/expo.coef.norm.rds")
expo.coef <- expo.coef[!expo.coef$term == "sd__(Intercept)",]
expo.coef <- expo.coef[!grepl("Error", expo.coef$term, fixed = T),]
expo.coef$estimate <- as.numeric(expo.coef$estimate)
expo.coef$std.error <- as.numeric(expo.coef$std.error)

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

alpha <- .05
expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

Les intervalles de confiance calculés avec la procédure Monte Carlo sont donnés sur la table \@ref(tab:coef-expo-ci-norm) (colonnes préfixées par "MC"). Nous avons également affiché les valeurs médianes des intervalles de confiance calculés à chaque répétition sur la base de la variation des coefficients d'exposition uniquement (colonne préfixées par "SE"). Il est flagrant que les intervalles Monte Carlo sont bien plus larges et ne permettent en aucun cas de conclure sur un effet de l'exposition sur l'émission de buzz.

```{r coef-expo-ci-norm}
kable(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint), "latex",
      col.names = c("MC - inf", "MC - sup", "SE - inf", "SE - sup"),
      caption = "Intervalles de confiance dans le cas de normales univariées",
      label = "coef-expo-ci-norm") %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"))
```

La figure \@ref(fig:coef-expo-ci-norm-dist) donne une représentation graphique de ces intervalles (en rouge les "MC" et en bleu les "SE"), ainsi que des distributions des coefficients.

```{r coef-expo-ci-norm-dist, fig.height = 6, fig.cap = "Intervalles de confiance dans le cas de normales univariées"}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_1$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_2$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_3$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

### Variation des coefficients selon une loi normale multivariée {#mvnorm}

L'une des explications aux très larges intervalles de confiance observés dans la section précédente pourrait être que nous avons accumulé les variances des coefficients sans tenir compte des probables covariances existant entre les coefficients. Afin de corriger cela nous avons répété l'approche décrite précédemment, mais en tirant les coefficients dans des lois normales multivariées (une pour les coefficients de la régression biexponentielle et une pour les coefficients de l'interpolation polynomiale) toujours centrées sur les estimations moyennes, mais ayant des matrices de variance-covariance non diagonales. Dorénavant nous avons donc une loi normale multivariée pour les coefficients de la régression biexponentielle et une autre pour la profondeur, les 2 étant de dimension 4.

```{r}
RegBiExp.vcov <- readRDS("../data/glmER_buzz_depth_maxlag/RegBiExp.vcov.rds")
ARcoefs <- rmvnorm(B, mean = RegBiExp.coefs$estimate, sigma = RegBiExp.vcov,
                   checkSymmetry = FALSE)
ARcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- BiExp(ARcoefs[b, 1], ARcoefs[b, 2], ARcoefs[b, 3], ARcoefs[b, 4],
                    lag = ARcoefs.fit$lag)
  data.frame(lag = ARcoefs.fit$lag, estimate = estimate, b = as.factor(b))
}))

estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
  glmer.coefs$estimate[2:5]
Depthcoefs.fit <- data.frame(depth = -1000:0, estimate = estimate)
Depth.vcov <- as.matrix(readRDS("../data/glmer_buzz_ARDepth/glmERBuzzARDepth.vcov.rds"))[2:5, 2:5]
Depthcoefs <- rmvnorm(B, mean = glmer.coefs$estimate[2:5], sigma = Depth.vcov,
                      checkSymmetry = FALSE)
Depthcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- as.matrix(ns(-1000:0, knots = c(-323, -158, -54))) %*%
    c(Depthcoefs[b, 1], Depthcoefs[b, 2], Depthcoefs[b, 3], Depthcoefs[b, 4])
  data.frame(depth = -1000:0, estimate = estimate, b = as.factor(b))
}))
```

La figure \@ref(fig:coef-ar-mvnorm) montre que la régression biexponentielle initiale est encore plus fidèlement suivie qu'auparavant.

```{r coef-ar-mvnorm, fig.cap = "Variation des coefficients autorégressifs selon une loi normale multivariée"}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_line(data = ARcoefs.fit.mc, aes(x = lag, y = estimate, group = b), alpha = .1, col = "red") +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

Et surtout, comme nous pouvons le voir sur la figure \@ref(fig:coef-depth-mvnorm), il en va de même pour la profondeur, alors que précédemment les tirages donnaient des courbes fortement éloignées de celle attendue.

```{r coef-depth-mvnorm, fig.cap = "Variation des coefficients de profondeur selon une loi normale multivariée"}
ggplot(Depthcoefs.fit) +
  geom_line(data = Depthcoefs.fit.mc, aes(x = depth, y = estimate, group = b), alpha = .1, col = "red") +
  geom_line(aes(x = depth, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Profondeur [mètres]", y = "ns")
```

```{r}
expo.coef <- readRDS("../data/glmer_buzz_ARDepth_expo_par/expo.coef.mvnorm.biexp.rds")
expo.coef <- expo.coef[!expo.coef$term == "sd__(Intercept)",]
expo.coef <- expo.coef[!grepl("Error", expo.coef$term, fixed = T),]
expo.coef$estimate <- as.numeric(expo.coef$estimate)
expo.coef$std.error <- as.numeric(expo.coef$std.error)

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

Sur la table \@ref(tab:coef-expo-ci-mvnorm) nous pouvons constater que les intervalles de confiance estimés en utilisant des lois normales multivariées sont nettement plus petits et peuvent conduire à conclure sur un effet de l'exposition sur l'émission de buzz.

```{r coef-expo-ci-mvnorm}
kable(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint), "latex",
      col.names = c("MC - inf", "MC - sup", "SE - inf", "SE - sup"),
      caption = "Intervalles de confiance dans le cas de normales multivariées",
      label = "coef-expo-ci-mvnorm") %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"))
```

Nous pouvons également voir sur la figure \@ref(fig:coef-expo-ci-mvnorm-dist) que les distributions semblent normales, contrairement à celles observées avec les lois univariées.

```{r coef-expo-ci-mvnorm-dist, fig.height = 6, fig.cap = "Intervalles de confiance dans le cas de normales multivariées"}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_1$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_2$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_3$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

#### Variance-covariance des coefficients autorégressifs et non des coefficients de la régression biexponentielle \newline

Bien que plus intéressante, la procédure que nous avons mise en place se base sur la matrice de variance-covariance des coefficients de la régression biexponentielle, ce qui signifie que nous ne captons pas directement la variabilité du phénomène autorégressif mais plutôt celle de la régression biexponentielle. Pour palier cette approximation nous avons tenté d'estimer la matrice de variance-covariance des coefficients autorégressifs, à nouveau par une procédure Monte Carlo. Cette fois-ci nous répétons 1000 fois le tirage des 60 coefficients de mémoire à partir d'une loi normale multivariée et à chaque fois nous ajustons une régression biexponentielle sur les 60 coefficients tirés ; finalement nous pouvons obtenir les estimations moyennes des coefficients de la biexponentielle, ainsi que la matrice de variance-covariance associée. Nous reprenons enfin la procédure Monte Carlo employée dans la section précédente avec le vecteur de moyennes et la matrice de variance-covariance obtenus.

```{r}
biexp.coef.cov <- readRDS("../data/glmer_biexp_AR_mc/biexp.coef.cov.rds")
biexp.coef.estimate <- readRDS("../data/glmer_biexp_AR_mc/biexp.coef.estimate.rds")
ARcoefs <- rmvnorm(B, mean = apply(biexp.coef.estimate, 2, mean),
                   sigma = biexp.coef.cov,
                   checkSymmetry = FALSE)
ARcoefs.fit.mc <- do.call(rbind, lapply(1:B, function(b) {
  estimate <- BiExp(ARcoefs[b, 1], ARcoefs[b, 3], ARcoefs[b, 2], ARcoefs[b, 4],
                    lag = ARcoefs.fit$lag)
  data.frame(lag = ARcoefs.fit$lag, estimate = estimate, b = as.factor(b))
}))
```

Nous pouvons contrôler sur la figure \@ref(fig:coef-ar-mvnorm-mc) que les régressions biexponentielles obtenues sont cohérentes.

```{r coef-ar-mvnorm-mc, fig.cap = "Variation des coefficients autorégressif selon une loi normale multivariée estimée par Monte Carlo"}
ggplot(ARcoefs.fit, aes(x = lag, y = truth)) +
  geom_line(data = ARcoefs.fit.mc, aes(x = lag, y = estimate, group = b), alpha = .1, col = "red") +
  geom_point(alpha = 0.5) +
  geom_line(aes(x = lag, y = estimate)) +
  geom_hline(yintercept = 0, alpha = .5, lty = 2) +
  labs(x = "Mémoire [secondes]", y = "Coefficient")
```

```{r}
expo.coef <- readRDS("../data/glmer_buzz_ARDepth_expo_par/expo.coef.mvnorm.mc.rds")
expo.coef <- expo.coef[!expo.coef$term == "sd__(Intercept)",]
expo.coef <- expo.coef[!grepl("Error", expo.coef$term, fixed = T),]
expo.coef$estimate <- as.numeric(expo.coef$estimate)
expo.coef$std.error <- as.numeric(expo.coef$std.error)

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

La table \@ref(tab:coef-expo-ci-mvnorm-mc) et la figure \@ref(fig:coef-expo-ci-mvnorm-dist-mc) permettent de vérifier que bien que les intervalles calculés ainsi sont légèrement plus grands que les précédents, ils permettent toujours d'interpréter les coefficients d'exposition ajustés par le modèle.

```{r coef-expo-ci-mvnorm-mc}
kable(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint), "latex",
      col.names = c("MC - inf", "MC - sup", "SE - inf", "SE - sup"),
      caption = "Intervalles de confiance dans le cas de normales multivariées",
      label = "coef-expo-ci-mvnorm-mc") %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"))
```

```{r coef-expo-ci-mvnorm-dist-mc, fig.height = 6, fig.cap = "Intervalles de confiance dans le cas de normales multivariées"}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_1$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_2$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_3$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

#### Sans passer par la régression biexponentielle \newline

L'intérêt de la régression biexponentielle était de :

1. réduire le temps d'ajustement des modèles linéaires,
2. éviter d'accumuler les variances des 60 coefficients de mémoire.

En fixant les coefficients autorégressifs, avoir 4 ou 60 coefficients pour la mémoire n'importe plus ; et en utilisant une loi normale multivariée, nous devrions également ne plus accumuler directement les variances des coefficients. Ainsi, nous avons tenté de nous passer de la régression biexponentielle, et donc de tirer les 60 coefficients mémoire et les 4 coefficients de profondeur directement dans une seule loi normale multivariée.

```{r}
expo.coef <- readRDS("../data/glmer_buzz_ARDepth_expo_par/expo.coef.mvnorm.rds")
expo.coef <- expo.coef[!expo.coef$term == "sd__(Intercept)",]
expo.coef <- expo.coef[!grepl("Error", expo.coef$term, fixed = T),]
expo.coef$estimate <- as.numeric(expo.coef$estimate)
expo.coef$std.error <- as.numeric(expo.coef$std.error)

expo.coef.estimate <- expo.coef[, c("term", "estimate")]
expo.coef.estimate$seq <- with(expo.coef.estimate, ave(estimate, term, FUN = seq_along))
expo.coef.estimate <- t(dcast(expo.coef.estimate, seq ~ term, value.var = "estimate")[, 2:5])
expo.coef.estimate.confint <- t(apply(expo.coef.estimate, 1, mc_percentile))

expo.coef.std.error <- expo.coef
expo.coef.std.error$seq <- with(expo.coef.std.error, ave(std.error, term, FUN = seq_along))
expo.coef.std.error$lower <-
  expo.coef.std.error$estimate - qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error$upper <-
  expo.coef.std.error$estimate + qnorm(1 - alpha / 2) * expo.coef.std.error$std.error
expo.coef.std.error.lower <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "lower")[, 2:5]),
                                   1, median)
expo.coef.std.error.upper <- apply(t(dcast(expo.coef.std.error, seq ~ term, value.var = "upper")[, 2:5]),
                                   1, median)
expo.coef.std.error.confint <- cbind(expo.coef.std.error.lower, expo.coef.std.error.upper)
```

Nous pouvons voir sur la table \@ref(tab:coef-expo-ci-mvnorm-full) et la figure \@ref(fig:coef-expo-ci-mvnorm-dist-full) qu'avec cette approche plus directe, les intervalles de confiance sont quasiment identiques à ceux obtenus dans la section \@ref(mvnorm), et même plus petit pour l'intercept.

```{r coef-expo-ci-mvnorm-full}
kable(cbind(expo.coef.estimate.confint, expo.coef.std.error.confint), "latex",
      col.names = c("MC - inf", "MC - sup", "SE - inf", "SE - sup"),
      caption = "Intervalles de confiance dans le cas de normales multivariées",
      label = "coef-expo-ci-mvnorm-full") %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"))
```

```{r coef-expo-ci-mvnorm-dist-full, fig.height = 6, fig.cap = "Intervalles de confiance dans le cas de normales multivariées"}
g1 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[1,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[1, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[1, 2], lty = 2, col = "blue") +
  labs(x = TeX("Intercept $\\beta_0$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 1, 0, "pt"))

g2 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[2,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[2, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[2, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_1$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 1, 0, "pt"))

g3 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[3,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[3, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[3, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_2$"), y = "Effectif") +
  theme(plot.margin = margin(0, 1, 0, 0, "pt"))

g4 <- ggplot() +
  geom_histogram(data = data.frame(coef = as.numeric(expo.coef.estimate[4,])),
                 aes(x = coef), position = "identity", col = "grey") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 1], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.estimate.confint[4, 2], lty = 2, col = "red") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 1], lty = 2, col = "blue") +
  geom_vline(xintercept = expo.coef.std.error.confint[4, 2], lty = 2, col = "blue") +
  labs(x = TeX("Exposition $\\beta_3$"), y = "Effectif") +
  theme(axis.title.y = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "pt"))

(g1 + g2) / (g3 + g4)
```

## Comparaison de l'estimation du taux d'émission de buzz avec et sans la profondeur

```{r}
predFrame <- readRDS("../data/glmer_buzz_ARDepth_expo_pred/predFrame.rds")
predFramePop <- readRDS("../data/glmer_buzz_ARDepth_expo_pred/predFramePop.rds")
ChangePop <- readRDS("../data/glmer_buzz_ARDepth_expo_pred/ChangePop.rds")
```

```{r}
ggplot(data = predFrame, aes(x = 1 / X, y = 60 * exp(predBuzz), color = Ind)) +
  geom_line() +
  geom_line(data = predFramePop, aes(x = 1 / X, y = 60 * exp(predBuzzPop)), size = 1.2, color = "black") +
  xlim(0, 50) +
  xlab("Distance avec le bateau (km)") +
  ylab("Taux d'émission de buzz (1/min)") +
  facet_grid(. ~ model)
```

```{r}
ggplot(data = ChangePop, aes(x = 1 / X, y = change, color = model)) +
  geom_line() +
  geom_ribbon(aes(ymin = change - CI, ymax = change + CI, fill = model), alpha = 0.5, linetype = 0) +
  xlim(0, 40) +
  xlab("Distance avec le bateau (km)") +
  ylab("Pourcentage de taux normal d'émission de buzz") +
  theme(legend.position = "top", legend.title = element_blank())
```
